{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Conv2D, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "\n",
    "data_dir = \"training_data\"\n",
    "processed_data_dir = \"processed_data\"\n",
    "raw_data_dirs = [\"raw_training_1_91_1st-P__norm-high99\",\n",
    "                 \"raw_training_2_173_1st-P__norm-high99\",\n",
    "                 \"raw_training_3_74_1st-P__norm-high99\",\n",
    "                 \"raw_training_4_8_3th-P__rev-high99\",\n",
    "                 \"raw_training_5_109_1st-P__rev-high99\",\n",
    "                 ##\"raw_training_6_143_1st-P__rev-high99_noHud\",\n",
    "                 ##\"raw_training_7_77_1st-P__norm-high99_noHud\",\n",
    "                 ##\"raw_training_8_53_1st-P__norm-high99_noHud\",\n",
    "                 ##\"raw_training_9_52_1st-P__rev-high99_noHud\",\n",
    "                ]\n",
    "\n",
    "raw_data_paths = [os.path.join(data_dir, train_dir) for train_dir in raw_data_dirs]\n",
    "processed_data_path = os.path.join(data_dir, processed_data_dir)\n",
    "\n",
    "raw_file_paths = []\n",
    "for directory in raw_data_paths:\n",
    "    paths = [os.path.join(directory, file.name) for file in os.scandir(directory)]\n",
    "    raw_file_paths += paths\n",
    "\n",
    "random.shuffle(raw_file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:25:30] File Processing is starting...\n",
      "\n",
      "[13:25:30][new file 1/19] New Array has been created...\n",
      "[13:25:30][new file 1/19] Loading, bluring and appending instances...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\env37\\lib\\site-packages\\ipykernel_launcher.py:46: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:25:33][new file 1/19] Data is getting scaled...\n",
      "[13:25:41][new file 1/19] key strokes are getting blured between frames...\n",
      "[13:25:41][new file 1/19] Instances get shuffled...\n",
      "[13:25:41][new file 1/19] \"blured12to1_withHud_25k__1of19__2021-02-02 13-25-30.npy\" is getting saved...this might take a while... (shape=(25000, 2))\n",
      "[13:25:49][new file 1/19] \"blured12to1_withHud_25k__1of19__2021-02-02 13-25-30.npy\" has been saved... shape=(25000, 2)\n",
      "\n",
      "[13:25:54][new file 2/19] New Array has been created...\n",
      "[13:25:54][new file 2/19] Loading, bluring and appending instances...\n",
      "[13:25:57][new file 2/19] Data is getting scaled...\n",
      "[13:26:05][new file 2/19] key strokes are getting blured between frames...\n",
      "[13:26:05][new file 2/19] Instances get shuffled...\n",
      "[13:26:05][new file 2/19] \"blured12to1_withHud_25k__2of19__2021-02-02 13-25-54.npy\" is getting saved...this might take a while... (shape=(25000, 2))\n",
      "[13:26:13][new file 2/19] \"blured12to1_withHud_25k__2of19__2021-02-02 13-25-54.npy\" has been saved... shape=(25000, 2)\n",
      "\n",
      "[13:26:18][new file 3/19] New Array has been created...\n",
      "[13:26:18][new file 3/19] Loading, bluring and appending instances...\n",
      "[13:26:49][new file 3/19] Data is getting scaled...\n",
      "[13:26:58][new file 3/19] key strokes are getting blured between frames...\n",
      "[13:26:58][new file 3/19] Instances get shuffled...\n",
      "[13:26:58][new file 3/19] \"blured12to1_withHud_25k__3of19__2021-02-02 13-26-18.npy\" is getting saved...this might take a while... (shape=(25000, 2))\n",
      "[13:27:10][new file 3/19] \"blured12to1_withHud_25k__3of19__2021-02-02 13-26-18.npy\" has been saved... shape=(25000, 2)\n",
      "\n",
      "[13:27:15][new file 4/19] New Array has been created...\n",
      "[13:27:15][new file 4/19] Loading, bluring and appending instances...\n",
      "[13:27:56][new file 4/19] Data is getting scaled...\n",
      "[13:28:05][new file 4/19] key strokes are getting blured between frames...\n",
      "[13:28:05][new file 4/19] Instances get shuffled...\n",
      "[13:28:05][new file 4/19] \"blured12to1_withHud_25k__4of19__2021-02-02 13-27-15.npy\" is getting saved...this might take a while... (shape=(25000, 2))\n",
      "[13:28:17][new file 4/19] \"blured12to1_withHud_25k__4of19__2021-02-02 13-27-15.npy\" has been saved... shape=(25000, 2)\n",
      "\n",
      "[13:28:22][new file 5/19] New Array has been created...\n",
      "[13:28:22][new file 5/19] Loading, bluring and appending instances...\n",
      "[13:29:04][new file 5/19] Data is getting scaled...\n",
      "[13:29:13][new file 5/19] key strokes are getting blured between frames...\n",
      "[13:29:13][new file 5/19] Instances get shuffled...\n",
      "[13:29:13][new file 5/19] \"blured12to1_withHud_25k__5of19__2021-02-02 13-28-22.npy\" is getting saved...this might take a while... (shape=(25000, 2))\n",
      "[13:29:22][new file 5/19] \"blured12to1_withHud_25k__5of19__2021-02-02 13-28-22.npy\" has been saved... shape=(25000, 2)\n",
      "\n",
      "[13:29:27][new file 6/19] New Array has been created...\n",
      "[13:29:27][new file 6/19] Loading, bluring and appending instances...\n",
      "[13:29:31][new file 6/19] Data is getting scaled...\n",
      "[13:29:40][new file 6/19] key strokes are getting blured between frames...\n",
      "[13:29:40][new file 6/19] Instances get shuffled...\n",
      "[13:29:40][new file 6/19] \"blured12to1_withHud_25k__6of19__2021-02-02 13-29-27.npy\" is getting saved...this might take a while... (shape=(25000, 2))\n",
      "[13:29:48][new file 6/19] \"blured12to1_withHud_25k__6of19__2021-02-02 13-29-27.npy\" has been saved... shape=(25000, 2)\n",
      "\n",
      "[13:29:54][new file 7/19] New Array has been created...\n",
      "[13:29:54][new file 7/19] Loading, bluring and appending instances...\n",
      "[13:29:57][new file 7/19] Data is getting scaled...\n",
      "[13:30:07][new file 7/19] key strokes are getting blured between frames...\n",
      "[13:30:07][new file 7/19] Instances get shuffled...\n",
      "[13:30:07][new file 7/19] \"blured12to1_withHud_25k__7of19__2021-02-02 13-29-54.npy\" is getting saved...this might take a while... (shape=(25000, 2))\n",
      "[13:30:15][new file 7/19] \"blured12to1_withHud_25k__7of19__2021-02-02 13-29-54.npy\" has been saved... shape=(25000, 2)\n",
      "\n",
      "[13:30:21][new file 8/19] New Array has been created...\n",
      "[13:30:21][new file 8/19] Loading, bluring and appending instances...\n",
      "[13:30:24][new file 8/19] Data is getting scaled...\n",
      "[13:30:31][new file 8/19] key strokes are getting blured between frames...\n",
      "[13:30:31][new file 8/19] Instances get shuffled...\n",
      "[13:30:31][new file 8/19] \"blured12to1_withHud_25k__8of19__2021-02-02 13-30-21.npy\" is getting saved...this might take a while... (shape=(25000, 2))\n",
      "[13:30:39][new file 8/19] \"blured12to1_withHud_25k__8of19__2021-02-02 13-30-21.npy\" has been saved... shape=(25000, 2)\n",
      "\n",
      "[13:30:44][new file 9/19] New Array has been created...\n",
      "[13:30:44][new file 9/19] Loading, bluring and appending instances...\n",
      "[13:30:47][new file 9/19] Data is getting scaled...\n",
      "[13:30:56][new file 9/19] key strokes are getting blured between frames...\n",
      "[13:30:56][new file 9/19] Instances get shuffled...\n",
      "[13:30:56][new file 9/19] \"blured12to1_withHud_25k__9of19__2021-02-02 13-30-44.npy\" is getting saved...this might take a while... (shape=(25000, 2))\n",
      "[13:31:04][new file 9/19] \"blured12to1_withHud_25k__9of19__2021-02-02 13-30-44.npy\" has been saved... shape=(25000, 2)\n",
      "\n",
      "[13:31:10][new file 10/19] New Array has been created...\n",
      "[13:31:10][new file 10/19] Loading, bluring and appending instances...\n",
      "[13:31:13][new file 10/19] Data is getting scaled...\n",
      "[13:31:22][new file 10/19] key strokes are getting blured between frames...\n",
      "[13:31:22][new file 10/19] Instances get shuffled...\n",
      "[13:31:22][new file 10/19] \"blured12to1_withHud_25k__10of19__2021-02-02 13-31-10.npy\" is getting saved...this might take a while... (shape=(25000, 2))\n",
      "[13:31:29][new file 10/19] \"blured12to1_withHud_25k__10of19__2021-02-02 13-31-10.npy\" has been saved... shape=(25000, 2)\n",
      "\n",
      "[13:31:35][new file 11/19] New Array has been created...\n",
      "[13:31:35][new file 11/19] Loading, bluring and appending instances...\n",
      "[13:31:39][new file 11/19] Data is getting scaled...\n",
      "[13:31:44][new file 11/19] key strokes are getting blured between frames...\n",
      "[13:31:44][new file 11/19] Instances get shuffled...\n",
      "[13:31:44][new file 11/19] \"blured12to1_withHud_25k__11of19__2021-02-02 13-31-35.npy\" is getting saved...this might take a while... (shape=(25000, 2))\n",
      "[13:31:52][new file 11/19] \"blured12to1_withHud_25k__11of19__2021-02-02 13-31-35.npy\" has been saved... shape=(25000, 2)\n",
      "\n",
      "[13:31:58][new file 12/19] New Array has been created...\n",
      "[13:31:58][new file 12/19] Loading, bluring and appending instances...\n",
      "[13:32:02][new file 12/19] Data is getting scaled...\n",
      "[13:32:11][new file 12/19] key strokes are getting blured between frames...\n",
      "[13:32:11][new file 12/19] Instances get shuffled...\n",
      "[13:32:12][new file 12/19] \"blured12to1_withHud_25k__12of19__2021-02-02 13-31-58.npy\" is getting saved...this might take a while... (shape=(25000, 2))\n",
      "[13:32:19][new file 12/19] \"blured12to1_withHud_25k__12of19__2021-02-02 13-31-58.npy\" has been saved... shape=(25000, 2)\n",
      "\n",
      "[13:32:25][new file 13/19] New Array has been created...\n",
      "[13:32:25][new file 13/19] Loading, bluring and appending instances...\n",
      "[13:32:29][new file 13/19] Data is getting scaled...\n",
      "[13:32:38][new file 13/19] key strokes are getting blured between frames...\n",
      "[13:32:38][new file 13/19] Instances get shuffled...\n",
      "[13:32:38][new file 13/19] \"blured12to1_withHud_25k__13of19__2021-02-02 13-32-25.npy\" is getting saved...this might take a while... (shape=(25000, 2))\n",
      "[13:32:53][new file 13/19] \"blured12to1_withHud_25k__13of19__2021-02-02 13-32-25.npy\" has been saved... shape=(25000, 2)\n",
      "\n",
      "[13:32:59][new file 14/19] New Array has been created...\n",
      "[13:32:59][new file 14/19] Loading, bluring and appending instances...\n",
      "[13:33:43][new file 14/19] Data is getting scaled...\n",
      "[13:33:52][new file 14/19] key strokes are getting blured between frames...\n",
      "[13:33:52][new file 14/19] Instances get shuffled...\n",
      "[13:33:52][new file 14/19] \"blured12to1_withHud_25k__14of19__2021-02-02 13-32-59.npy\" is getting saved...this might take a while... (shape=(25000, 2))\n",
      "[13:34:04][new file 14/19] \"blured12to1_withHud_25k__14of19__2021-02-02 13-32-59.npy\" has been saved... shape=(25000, 2)\n",
      "\n",
      "[13:34:09][new file 15/19] New Array has been created...\n",
      "[13:34:09][new file 15/19] Loading, bluring and appending instances...\n",
      "[13:34:58][new file 15/19] Data is getting scaled...\n",
      "[13:35:07][new file 15/19] key strokes are getting blured between frames...\n",
      "[13:35:07][new file 15/19] Instances get shuffled...\n",
      "[13:35:07][new file 15/19] \"blured12to1_withHud_25k__15of19__2021-02-02 13-34-09.npy\" is getting saved...this might take a while... (shape=(25000, 2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:35:19][new file 15/19] \"blured12to1_withHud_25k__15of19__2021-02-02 13-34-09.npy\" has been saved... shape=(25000, 2)\n",
      "\n",
      "[13:35:25][new file 16/19] New Array has been created...\n",
      "[13:35:25][new file 16/19] Loading, bluring and appending instances...\n",
      "[13:36:13][new file 16/19] Data is getting scaled...\n",
      "[13:36:22][new file 16/19] key strokes are getting blured between frames...\n",
      "[13:36:22][new file 16/19] Instances get shuffled...\n",
      "[13:36:22][new file 16/19] \"blured12to1_withHud_25k__16of19__2021-02-02 13-35-25.npy\" is getting saved...this might take a while... (shape=(25000, 2))\n",
      "[13:36:34][new file 16/19] \"blured12to1_withHud_25k__16of19__2021-02-02 13-35-25.npy\" has been saved... shape=(25000, 2)\n",
      "\n",
      "[13:36:39][new file 17/19] New Array has been created...\n",
      "[13:36:39][new file 17/19] Loading, bluring and appending instances...\n",
      "[13:37:25][new file 17/19] Data is getting scaled...\n",
      "[13:37:30][new file 17/19] key strokes are getting blured between frames...\n",
      "[13:37:30][new file 17/19] Instances get shuffled...\n",
      "[13:37:31][new file 17/19] \"blured12to1_withHud_25k__17of19__2021-02-02 13-36-39.npy\" is getting saved...this might take a while... (shape=(25000, 2))\n",
      "[13:37:44][new file 17/19] \"blured12to1_withHud_25k__17of19__2021-02-02 13-36-39.npy\" has been saved... shape=(25000, 2)\n",
      "\n",
      "[13:37:51][new file 18/19] New Array has been created...\n",
      "[13:37:51][new file 18/19] Loading, bluring and appending instances...\n",
      "[13:38:35][new file 18/19] Data is getting scaled...\n",
      "[13:38:44][new file 18/19] key strokes are getting blured between frames...\n",
      "[13:38:44][new file 18/19] Instances get shuffled...\n",
      "[13:38:44][new file 18/19] \"blured12to1_withHud_25k__18of19__2021-02-02 13-37-51.npy\" is getting saved...this might take a while... (shape=(25000, 2))\n",
      "[13:38:57][new file 18/19] \"blured12to1_withHud_25k__18of19__2021-02-02 13-37-51.npy\" has been saved... shape=(25000, 2)\n",
      "\n",
      "[13:39:03][new file 19/19] New Array has been created...\n",
      "[13:39:03][new file 19/19] Loading, bluring and appending instances...\n",
      "[13:39:20][new file 19/19] Data is getting scaled...\n",
      "[13:39:21][new file 19/19] key strokes are getting blured between frames...\n",
      "[13:39:21][new file 19/19] Instances get shuffled...\n",
      "[13:39:21][new file 19/19] \"blured12to1_withHud_25k__19of19__2021-02-02 13-39-03.npy\" is getting saved...this might take a while... (shape=(5000, 2))\n",
      "[13:39:23][new file 19/19] \"blured12to1_withHud_25k__19of19__2021-02-02 13-39-03.npy\" has been saved... shape=(5000, 2)\n",
      "\n",
      "\n",
      "\n",
      "[13:39:23]File Processing has been finished...\n"
     ]
    }
   ],
   "source": [
    "# Process Raw Training Files\n",
    "\n",
    "# 0) Setup parameters and variables\n",
    "# 1) Iterate through raw_training_files.\n",
    "# 2) Blur the keyboard strokes with close instances\n",
    "# 3) Append file to bigger output file\n",
    "# 4) Scale input values by 255.\n",
    "# 5) Shuffle instances within the new files.\n",
    "# 6) Save new files as processed.\n",
    "\n",
    "# 0) Set Parameters\n",
    "blur_321 = list(range(3, 0, -1))\n",
    "blur_6to1 =list(range(6, 0, -1))\n",
    "blur_12to1 =list(range(12, 0, -1))\n",
    "blur_24to1 =list(range(24, 0, -1))\n",
    "\n",
    "blur = blur_12to1\n",
    "\n",
    "n_combined_files = 25\n",
    "n_output_files = ceil(len(raw_file_paths)/n_combined_files)\n",
    "\n",
    "\n",
    "print(f\"[{datetime.now().strftime('%H:%M:%S')}] File Processing is starting...\")\n",
    "\n",
    "# 1) Iterate over number of output files\n",
    "for j in range(n_output_files):\n",
    "    blured_train_file = None\n",
    "    print(f\"\\n[{datetime.now().strftime('%H:%M:%S')}][new file {j+1}/{n_output_files}] New Array has been created...\")\n",
    "    processed_file_name = f\"blured12to1_withHud_25k__{j+1}of{n_output_files}__{datetime.now().strftime('%Y-%m-%d %H-%M-%S')}.npy\"\n",
    "    processed_file_path = os.path.join(processed_data_path, processed_file_name)\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}][new file {j+1}/{n_output_files}] Loading, bluring and appending instances...\")\n",
    "    \n",
    "    # 1) Iterate over each inp-file of out-file\n",
    "    for i in range(0, n_combined_files):\n",
    "        index = j*n_combined_files+i\n",
    "        if index >= len(raw_file_paths):\n",
    "               break\n",
    "        file = np.load(raw_file_paths[index], allow_pickle=True)\n",
    "        \n",
    "        # 2) Blur\n",
    "        blured_keys = blur_lists_of_list([instance[1] for instance in file], blur)\n",
    "        file = [[file[i][0], blured_keys[i]] for i in range(len(file))]\n",
    "        del blured_keys\n",
    "        \n",
    "        # 3) Append\n",
    "        if blured_train_file == None:\n",
    "            blured_train_file = file\n",
    "        else:\n",
    "            blured_train_file = np.append(blured_train_file, file, axis=0)\n",
    "        #print(np.shape(blured_train_file))\n",
    "        del file\n",
    "\n",
    "    # 4) Scale\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}][new file {j+1}/{n_output_files}] Data is getting scaled...\")\n",
    "    for i in range(len(blured_train_file)):\n",
    "        blured_train_file[i][0] = blured_train_file[i][0] / 255\n",
    "        ##unblured_train_file = blured_train_file.copy()\n",
    "\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}][new file {j+1}/{n_output_files}] key strokes are getting blured between frames...\")\n",
    "\n",
    "\n",
    "    # 5) Shuffle\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}][new file {j+1}/{n_output_files}] Instances get shuffled...\")\n",
    "    np.random.shuffle(blured_train_file)\n",
    "\n",
    "    # 6) Save\n",
    "    print(f'[{datetime.now().strftime(\"%H:%M:%S\")}][new file {j+1}/{n_output_files}] \"{processed_file_name}\" is getting saved...this might take a while... (shape={np.shape(blured_train_file)})')\n",
    "    np.save(processed_file_path, blured_train_file)\n",
    "    print(f'[{datetime.now().strftime(\"%H:%M:%S\")}][new file {j+1}/{n_output_files}] \"{processed_file_name}\" has been saved... shape={np.shape(blured_train_file)}')\n",
    "    del blured_train_file\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(f\"[{datetime.now().strftime('%H:%M:%S')}]File Processing has been finished...\")\n",
    "\n",
    "# CHECK IF FILE WAS CORRECTLY BLURRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blur Lists and 2d-Lists\n",
    "\n",
    "blured_list = []\n",
    "\n",
    "def blur_list(inp_list, blur_weights):\n",
    "    blured_list = []\n",
    "    div_factor = blur_weights[0] + sum(blur_weights[1:]) * 2\n",
    "    for index in range(len(inp_list)):\n",
    "        for offset, blur_weight in enumerate(blur_weights):\n",
    "            if offset == 0:\n",
    "                blured_val = blur_weight * inp_list[index]\n",
    "            else:\n",
    "                if index + offset < len(inp_list):\n",
    "                    blured_val += blur_weight * inp_list[index+offset]\n",
    "                else:\n",
    "                    blured_val += blur_weight * inp_list[index]\n",
    "\n",
    "                if index - offset >= 0:\n",
    "                    blured_val += blur_weight * inp_list[index-offset]\n",
    "                else:\n",
    "                    blured_val += blur_weight * inp_list[index]\n",
    "            #print(blured_val)\n",
    "\n",
    "        blured_val /= div_factor\n",
    "        blured_list.append(blured_val)\n",
    "    \n",
    "    return blured_list\n",
    "    \n",
    "\n",
    "def blur_lists_of_list(list2d, blur_weights):\n",
    "    blured_list = []\n",
    "    for key_index in range(len(list2d[0])):\n",
    "        key_list = [instance[key_index] for instance in list2d]\n",
    "        key_list_blured = blur_list(key_list, blur_weights)\n",
    "            \n",
    "        if key_index == 0:\n",
    "            blured_list = [[val] for val in key_list_blured]\n",
    "        else:\n",
    "            for i in range(len(blured_list)):\n",
    "                blured_list[i].append(key_list_blured[i])\n",
    "                    \n",
    "    return blured_list\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process imported data\n",
    "\n",
    "proc_file_path = os.path.join(processed_data_path, \"blured6to1_withHud_25k__1of19__2021-02-02 12-42-57.npy\")\n",
    "\n",
    "# Load file\n",
    "training_data = np.load(proc_file_path, allow_pickle=True)\n",
    "# \"Split\" into input(X) and output(y)\n",
    "X = np.array([instance[0] for instance in training_data])\n",
    "y = np.array([instance[1] for instance in training_data])\n",
    "## del training_data\n",
    "\n",
    "# Create train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Add dimension for compatibility with keras CNN model\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "X_test = np.expand_dims(X_test, -1)\n",
    "\n",
    "# delete unused variables for saving ram\n",
    "del X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# show a random instance\n",
    "show_instance(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model\n",
    "\n",
    "def create_new_model():\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(64, 7, activation=\"relu\", padding=\"same\"),\n",
    "        keras.layers.MaxPooling2D(2),\n",
    "        keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "        keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "        keras.layers.MaxPooling2D(2),\n",
    "        #keras.layers.Dropout(0.5),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(128, activation=\"relu\"),\n",
    "        keras.layers.Dense(64, activation=\"relu\"),\n",
    "        #keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(4, activation=\"linear\")\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='mae',\n",
    "                  optimizer='adam',\n",
    "#                  metrics=['accuracy']\n",
    "                 )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 240, 100, 64)      1664      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 120, 50, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 120, 50, 128)      73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 60, 25, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 60, 25, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 30, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 46080)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               5898368   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 6,129,988\n",
      "Trainable params: 6,129,988\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create Model\n",
    "\n",
    "def create_deeper_model():\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Input(shape=(240, 100, 1)),\n",
    "        keras.layers.Conv2D(64, 5, activation=\"relu\", padding=\"same\"),\n",
    "        keras.layers.MaxPooling2D(2),\n",
    "        keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "        keras.layers.MaxPooling2D(2),\n",
    "        keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "        keras.layers.MaxPooling2D(2),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(128, activation=\"relu\"),\n",
    "        keras.layers.Dense(64, activation=\"relu\"),\n",
    "        keras.layers.Dense(4, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='mae',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['mae', 'mse', 'accuracy']\n",
    "                 )\n",
    "    return model\n",
    "\n",
    "model = create_deeper_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train Model\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 1\n",
    "patience = 5\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=patience),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "\n",
    "history = model.fit(X_train , y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:19:18] Training is starting...\n",
      "\n",
      "\n",
      "[14:19:18] Epoch 1 of 3 is starting...\n",
      "\n",
      "[14:19:18][epoch 1/3 | file 1/19] Loading and preparing \"blured12to1_withHud_25k__18of19__2021-02-02 13-37-51.npy\"...\n",
      "[14:19:41][epoch 1/3 | file 1/19] Training model...\n",
      "Epoch 1/3\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 240, 100, 1) for input Tensor(\"input_4:0\", shape=(None, 240, 100, 1), dtype=float32), but it was called on an input with incompatible shape (None, 100, 240, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 240, 100, 1) for input Tensor(\"input_4:0\", shape=(None, 240, 100, 1), dtype=float32), but it was called on an input with incompatible shape (None, 100, 240, 1).\n",
      "  2/352 [..............................] - ETA: 27s - loss: 0.3453 - mae: 0.3453 - mse: 0.1420 - accuracy: 0.6875WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0359s vs `on_train_batch_end` time: 0.0628s). Check your callbacks.\n",
      "352/352 [==============================] - ETA: 0s - loss: 0.0685 - mae: 0.0685 - mse: 0.0300 - accuracy: 0.9471WARNING:tensorflow:Model was constructed with shape (None, 240, 100, 1) for input Tensor(\"input_4:0\", shape=(None, 240, 100, 1), dtype=float32), but it was called on an input with incompatible shape (None, 100, 240, 1).\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0685 - mae: 0.0685 - mse: 0.0300 - accuracy: 0.9471 - val_loss: 0.0674 - val_mae: 0.0674 - val_mse: 0.0298 - val_accuracy: 0.9456\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 34s 96ms/step - loss: 0.0669 - mae: 0.0669 - mse: 0.0294 - accuracy: 0.9486 - val_loss: 0.0674 - val_mae: 0.0674 - val_mse: 0.0298 - val_accuracy: 0.9456\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0669 - mae: 0.0669 - mse: 0.0294 - accuracy: 0.9486 - val_loss: 0.0674 - val_mae: 0.0674 - val_mse: 0.0298 - val_accuracy: 0.9456\n",
      "[14:21:24][epoch 1/3 | file 1/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[14:21:26][epoch 1/3 | file 2/19] Loading and preparing \"blured12to1_withHud_25k__13of19__2021-02-02 13-32-25.npy\"...\n",
      "[14:21:43][epoch 1/3 | file 2/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 27s - loss: 0.0626 - mae: 0.0626 - mse: 0.0231 - accuracy: 0.9688WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0354s vs `on_train_batch_end` time: 0.0608s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0572 - mae: 0.0572 - mse: 0.0213 - accuracy: 0.9748 - val_loss: 0.0588 - val_mae: 0.0588 - val_mse: 0.0226 - val_accuracy: 0.9716\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0572 - mae: 0.0572 - mse: 0.0213 - accuracy: 0.9748 - val_loss: 0.0588 - val_mae: 0.0588 - val_mse: 0.0226 - val_accuracy: 0.9716\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0572 - mae: 0.0572 - mse: 0.0213 - accuracy: 0.9748 - val_loss: 0.0588 - val_mae: 0.0588 - val_mse: 0.0226 - val_accuracy: 0.9716\n",
      "[14:23:28][epoch 1/3 | file 2/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[14:23:29][epoch 1/3 | file 3/19] Loading and preparing \"blured12to1_withHud_25k__6of19__2021-02-02 13-29-27.npy\"...\n",
      "[14:23:52][epoch 1/3 | file 3/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 28s - loss: 0.1098 - mae: 0.1098 - mse: 0.0710 - accuracy: 0.7891WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0359s vs `on_train_batch_end` time: 0.0628s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.1001 - mae: 0.1001 - mse: 0.0624 - accuracy: 0.8332 - val_loss: 0.1024 - val_mae: 0.1024 - val_mse: 0.0647 - val_accuracy: 0.8284\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 34s 98ms/step - loss: 0.1001 - mae: 0.1001 - mse: 0.0624 - accuracy: 0.8332 - val_loss: 0.1024 - val_mae: 0.1024 - val_mse: 0.0647 - val_accuracy: 0.8284\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.1001 - mae: 0.1001 - mse: 0.0624 - accuracy: 0.8332 - val_loss: 0.1024 - val_mae: 0.1024 - val_mse: 0.0647 - val_accuracy: 0.8284\n",
      "[14:25:37][epoch 1/3 | file 3/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[14:25:38][epoch 1/3 | file 4/19] Loading and preparing \"blured12to1_withHud_25k__10of19__2021-02-02 13-31-10.npy\"...\n",
      "[14:25:58][epoch 1/3 | file 4/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 28s - loss: 0.0876 - mae: 0.0876 - mse: 0.0496 - accuracy: 0.8594WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0359s vs `on_train_batch_end` time: 0.0628s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0751 - mae: 0.0751 - mse: 0.0386 - accuracy: 0.9120 - val_loss: 0.0768 - val_mae: 0.0768 - val_mse: 0.0395 - val_accuracy: 0.9104\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 98ms/step - loss: 0.0751 - mae: 0.0751 - mse: 0.0386 - accuracy: 0.9120 - val_loss: 0.0768 - val_mae: 0.0768 - val_mse: 0.0395 - val_accuracy: 0.9104\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0751 - mae: 0.0751 - mse: 0.0386 - accuracy: 0.9120 - val_loss: 0.0768 - val_mae: 0.0768 - val_mse: 0.0395 - val_accuracy: 0.9104\n",
      "[14:27:43][epoch 1/3 | file 4/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[14:27:44][epoch 1/3 | file 5/19] Loading and preparing \"blured12to1_withHud_25k__15of19__2021-02-02 13-34-09.npy\"...\n",
      "[14:28:07][epoch 1/3 | file 5/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 27s - loss: 0.0502 - mae: 0.0502 - mse: 0.0152 - accuracy: 0.9922WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0359s vs `on_train_batch_end` time: 0.0608s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0573 - mae: 0.0573 - mse: 0.0222 - accuracy: 0.9735 - val_loss: 0.0565 - val_mae: 0.0565 - val_mse: 0.0220 - val_accuracy: 0.9740ae: 0.0573 - mse: 0.0222 - ac\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 98ms/step - loss: 0.0573 - mae: 0.0573 - mse: 0.0222 - accuracy: 0.9735 - val_loss: 0.0565 - val_mae: 0.0565 - val_mse: 0.0220 - val_accuracy: 0.9740\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0573 - mae: 0.0573 - mse: 0.0222 - accuracy: 0.9735 - val_loss: 0.0565 - val_mae: 0.0565 - val_mse: 0.0220 - val_accuracy: 0.9740\n",
      "[14:29:52][epoch 1/3 | file 5/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[14:29:54][epoch 1/3 | file 6/19] Loading and preparing \"blured12to1_withHud_25k__7of19__2021-02-02 13-29-54.npy\"...\n",
      "[14:30:16][epoch 1/3 | file 6/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 28s - loss: 0.0771 - mae: 0.0771 - mse: 0.0418 - accuracy: 0.9219WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0359s vs `on_train_batch_end` time: 0.0628s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0713 - mae: 0.0713 - mse: 0.0352 - accuracy: 0.9302 - val_loss: 0.0691 - val_mae: 0.0691 - val_mse: 0.0333 - val_accuracy: 0.9324\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 98ms/step - loss: 0.0713 - mae: 0.0713 - mse: 0.0352 - accuracy: 0.9302 - val_loss: 0.0691 - val_mae: 0.0691 - val_mse: 0.0333 - val_accuracy: 0.9324\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0713 - mae: 0.0713 - mse: 0.0352 - accuracy: 0.9302 - val_loss: 0.0691 - val_mae: 0.0691 - val_mse: 0.0333 - val_accuracy: 0.9324\n",
      "[14:32:01][epoch 1/3 | file 6/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[14:32:02][epoch 1/3 | file 7/19] Loading and preparing \"blured12to1_withHud_25k__14of19__2021-02-02 13-32-59.npy\"...\n",
      "[14:32:25][epoch 1/3 | file 7/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 27s - loss: 0.0607 - mae: 0.0607 - mse: 0.0262 - accuracy: 0.9531WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0349s vs `on_train_batch_end` time: 0.0628s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0673 - mae: 0.0673 - mse: 0.0312 - accuracy: 0.9429 - val_loss: 0.0673 - val_mae: 0.0673 - val_mse: 0.0309 - val_accuracy: 0.9396\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 98ms/step - loss: 0.0673 - mae: 0.0673 - mse: 0.0312 - accuracy: 0.9429 - val_loss: 0.0673 - val_mae: 0.0673 - val_mse: 0.0309 - val_accuracy: 0.9396\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0673 - mae: 0.0673 - mse: 0.0312 - accuracy: 0.9429 - val_loss: 0.0673 - val_mae: 0.0673 - val_mse: 0.0309 - val_accuracy: 0.9396\n",
      "[14:34:10][epoch 1/3 | file 7/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[14:34:11][epoch 1/3 | file 8/19] Loading and preparing \"blured12to1_withHud_25k__12of19__2021-02-02 13-31-58.npy\"...\n",
      "[14:34:33][epoch 1/3 | file 8/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 28s - loss: 0.0571 - mae: 0.0571 - mse: 0.0214 - accuracy: 0.9844WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0359s vs `on_train_batch_end` time: 0.0628s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0628 - mae: 0.0628 - mse: 0.0241 - accuracy: 0.9700 - val_loss: 0.0625 - val_mae: 0.0625 - val_mse: 0.0242 - val_accuracy: 0.9688\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0628 - mae: 0.0628 - mse: 0.0241 - accuracy: 0.9700 - val_loss: 0.0625 - val_mae: 0.0625 - val_mse: 0.0242 - val_accuracy: 0.9688\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0628 - mae: 0.0628 - mse: 0.0241 - accuracy: 0.9700 - val_loss: 0.0625 - val_mae: 0.0625 - val_mse: 0.0242 - val_accuracy: 0.9688\n",
      "[14:36:18][epoch 1/3 | file 8/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[14:36:20][epoch 1/3 | file 9/19] Loading and preparing \"blured12to1_withHud_25k__19of19__2021-02-02 13-39-03.npy\"...\n",
      "[14:36:24][epoch 1/3 | file 9/19] Training model...\n",
      "Epoch 1/3\n",
      " 2/71 [..............................] - ETA: 5s - loss: 0.0553 - mae: 0.0553 - mse: 0.0203 - accuracy: 0.9766WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0349s vs `on_train_batch_end` time: 0.0633s). Check your callbacks.\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 0.0685 - mae: 0.0685 - mse: 0.0297 - accuracy: 0.9462 - val_loss: 0.0732 - val_mae: 0.0732 - val_mse: 0.0338 - val_accuracy: 0.9360\n",
      "Epoch 2/3\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 0.0685 - mae: 0.0685 - mse: 0.0297 - accuracy: 0.9462 - val_loss: 0.0732 - val_mae: 0.0732 - val_mse: 0.0338 - val_accuracy: 0.9360\n",
      "Epoch 3/3\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 0.0685 - mae: 0.0685 - mse: 0.0297 - accuracy: 0.9462 - val_loss: 0.0732 - val_mae: 0.0732 - val_mse: 0.0338 - val_accuracy: 0.9360\n",
      "[14:36:45][epoch 1/3 | file 9/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[14:36:46][epoch 1/3 | file 10/19] Loading and preparing \"blured12to1_withHud_25k__1of19__2021-02-02 13-25-30.npy\"...\n",
      "[14:37:09][epoch 1/3 | file 10/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 28s - loss: 0.0656 - mae: 0.0656 - mse: 0.0330 - accuracy: 0.9375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0359s vs `on_train_batch_end` time: 0.0638s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 98ms/step - loss: 0.0666 - mae: 0.0666 - mse: 0.0308 - accuracy: 0.9415 - val_loss: 0.0647 - val_mae: 0.0647 - val_mse: 0.0289 - val_accuracy: 0.9484\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0666 - mae: 0.0666 - mse: 0.0308 - accuracy: 0.9415 - val_loss: 0.0647 - val_mae: 0.0647 - val_mse: 0.0289 - val_accuracy: 0.9484\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0666 - mae: 0.0666 - mse: 0.0308 - accuracy: 0.9415 - val_loss: 0.0647 - val_mae: 0.0647 - val_mse: 0.0289 - val_accuracy: 0.9484\n",
      "[14:38:54][epoch 1/3 | file 10/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[14:38:56][epoch 1/3 | file 11/19] Loading and preparing \"blured12to1_withHud_25k__3of19__2021-02-02 13-26-18.npy\"...\n",
      "[14:39:18][epoch 1/3 | file 11/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 28s - loss: 0.0544 - mae: 0.0544 - mse: 0.0196 - accuracy: 0.9766WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0349s vs `on_train_batch_end` time: 0.0638s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0647 - mae: 0.0647 - mse: 0.0293 - accuracy: 0.9412 - val_loss: 0.0651 - val_mae: 0.0651 - val_mse: 0.0293 - val_accuracy: 0.9432\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0647 - mae: 0.0647 - mse: 0.0293 - accuracy: 0.9412 - val_loss: 0.0651 - val_mae: 0.0651 - val_mse: 0.0293 - val_accuracy: 0.9432\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0647 - mae: 0.0647 - mse: 0.0293 - accuracy: 0.9412 - val_loss: 0.0651 - val_mae: 0.0651 - val_mse: 0.0293 - val_accuracy: 0.9432\n",
      "[14:41:04][epoch 1/3 | file 11/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[14:41:05][epoch 1/3 | file 12/19] Loading and preparing \"blured12to1_withHud_25k__5of19__2021-02-02 13-28-22.npy\"...\n",
      "[14:41:28][epoch 1/3 | file 12/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 27s - loss: 0.0521 - mae: 0.0521 - mse: 0.0156 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0334s vs `on_train_batch_end` time: 0.0618s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0577 - mae: 0.0577 - mse: 0.0207 - accuracy: 0.9773 - val_loss: 0.0579 - val_mae: 0.0579 - val_mse: 0.0209 - val_accuracy: 0.9792\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0577 - mae: 0.0577 - mse: 0.0207 - accuracy: 0.9773 - val_loss: 0.0579 - val_mae: 0.0579 - val_mse: 0.0209 - val_accuracy: 0.9792\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0577 - mae: 0.0577 - mse: 0.0207 - accuracy: 0.9773 - val_loss: 0.0579 - val_mae: 0.0579 - val_mse: 0.0209 - val_accuracy: 0.9792\n",
      "[14:43:13][epoch 1/3 | file 12/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[14:43:15][epoch 1/3 | file 13/19] Loading and preparing \"blured12to1_withHud_25k__9of19__2021-02-02 13-30-44.npy\"...\n",
      "[14:43:37][epoch 1/3 | file 13/19] Training model...\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2/352 [..............................] - ETA: 27s - loss: 0.0665 - mae: 0.0665 - mse: 0.0289 - accuracy: 0.9609WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0359s vs `on_train_batch_end` time: 0.0608s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0657 - mae: 0.0657 - mse: 0.0280 - accuracy: 0.9604 - val_loss: 0.0659 - val_mae: 0.0659 - val_mse: 0.0288 - val_accuracy: 0.9604\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 98ms/step - loss: 0.0657 - mae: 0.0657 - mse: 0.0280 - accuracy: 0.9604 - val_loss: 0.0659 - val_mae: 0.0659 - val_mse: 0.0288 - val_accuracy: 0.9604\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0657 - mae: 0.0657 - mse: 0.0280 - accuracy: 0.9604 - val_loss: 0.0659 - val_mae: 0.0659 - val_mse: 0.0288 - val_accuracy: 0.9604\n",
      "[14:45:22][epoch 1/3 | file 13/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[14:45:24][epoch 1/3 | file 14/19] Loading and preparing \"blured12to1_withHud_25k__16of19__2021-02-02 13-35-25.npy\"...\n",
      "[14:45:46][epoch 1/3 | file 14/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 27s - loss: 0.0710 - mae: 0.0710 - mse: 0.0320 - accuracy: 0.9531WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0339s vs `on_train_batch_end` time: 0.0618s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0716 - mae: 0.0716 - mse: 0.0349 - accuracy: 0.9332 - val_loss: 0.0707 - val_mae: 0.0707 - val_mse: 0.0339 - val_accuracy: 0.9356\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 98ms/step - loss: 0.0716 - mae: 0.0716 - mse: 0.0349 - accuracy: 0.9332 - val_loss: 0.0707 - val_mae: 0.0707 - val_mse: 0.0339 - val_accuracy: 0.9356\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0716 - mae: 0.0716 - mse: 0.0349 - accuracy: 0.9332 - val_loss: 0.0707 - val_mae: 0.0707 - val_mse: 0.0339 - val_accuracy: 0.9356\n",
      "[14:47:31][epoch 1/3 | file 14/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[14:47:33][epoch 1/3 | file 15/19] Loading and preparing \"blured12to1_withHud_25k__2of19__2021-02-02 13-25-54.npy\"...\n",
      "[14:47:55][epoch 1/3 | file 15/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 27s - loss: 0.0671 - mae: 0.0671 - mse: 0.0352 - accuracy: 0.9141WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0349s vs `on_train_batch_end` time: 0.0633s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0729 - mae: 0.0729 - mse: 0.0365 - accuracy: 0.9236 - val_loss: 0.0686 - val_mae: 0.0686 - val_mse: 0.0322 - val_accuracy: 0.9368\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 98ms/step - loss: 0.0729 - mae: 0.0729 - mse: 0.0365 - accuracy: 0.9236 - val_loss: 0.0686 - val_mae: 0.0686 - val_mse: 0.0322 - val_accuracy: 0.9368\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0729 - mae: 0.0729 - mse: 0.0365 - accuracy: 0.9236 - val_loss: 0.0686 - val_mae: 0.0686 - val_mse: 0.0322 - val_accuracy: 0.9368\n",
      "[14:49:40][epoch 1/3 | file 15/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[14:49:41][epoch 1/3 | file 16/19] Loading and preparing \"blured12to1_withHud_25k__11of19__2021-02-02 13-31-35.npy\"...\n",
      "[14:50:04][epoch 1/3 | file 16/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 28s - loss: 0.0614 - mae: 0.0614 - mse: 0.0257 - accuracy: 0.9609WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0359s vs `on_train_batch_end` time: 0.0628s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0605 - mae: 0.0605 - mse: 0.0239 - accuracy: 0.9726 - val_loss: 0.0585 - val_mae: 0.0585 - val_mse: 0.0218 - val_accuracy: 0.9800\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 98ms/step - loss: 0.0605 - mae: 0.0605 - mse: 0.0239 - accuracy: 0.9726 - val_loss: 0.0585 - val_mae: 0.0585 - val_mse: 0.0218 - val_accuracy: 0.9800\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0605 - mae: 0.0605 - mse: 0.0239 - accuracy: 0.9726 - val_loss: 0.0585 - val_mae: 0.0585 - val_mse: 0.0218 - val_accuracy: 0.9800\n",
      "[14:51:49][epoch 1/3 | file 16/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[14:51:50][epoch 1/3 | file 17/19] Loading and preparing \"blured12to1_withHud_25k__4of19__2021-02-02 13-27-15.npy\"...\n",
      "[14:52:12][epoch 1/3 | file 17/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 27s - loss: 0.0603 - mae: 0.0603 - mse: 0.0279 - accuracy: 0.9375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0354s vs `on_train_batch_end` time: 0.0608s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0626 - mae: 0.0626 - mse: 0.0257 - accuracy: 0.9588 - val_loss: 0.0639 - val_mae: 0.0639 - val_mse: 0.0261 - val_accuracy: 0.9572\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0626 - mae: 0.0626 - mse: 0.0257 - accuracy: 0.9588 - val_loss: 0.0639 - val_mae: 0.0639 - val_mse: 0.0261 - val_accuracy: 0.9572\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0626 - mae: 0.0626 - mse: 0.0257 - accuracy: 0.9588 - val_loss: 0.0639 - val_mae: 0.0639 - val_mse: 0.0261 - val_accuracy: 0.9572\n",
      "[14:53:57][epoch 1/3 | file 17/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[14:53:59][epoch 1/3 | file 18/19] Loading and preparing \"blured12to1_withHud_25k__8of19__2021-02-02 13-30-21.npy\"...\n",
      "[14:54:21][epoch 1/3 | file 18/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 27s - loss: 0.0603 - mae: 0.0603 - mse: 0.0236 - accuracy: 0.9688WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0359s vs `on_train_batch_end` time: 0.0628s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0637 - mae: 0.0637 - mse: 0.0258 - accuracy: 0.9619 - val_loss: 0.0649 - val_mae: 0.0649 - val_mse: 0.0267 - val_accuracy: 0.9608\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0637 - mae: 0.0637 - mse: 0.0258 - accuracy: 0.9619 - val_loss: 0.0649 - val_mae: 0.0649 - val_mse: 0.0267 - val_accuracy: 0.9608\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0637 - mae: 0.0637 - mse: 0.0258 - accuracy: 0.9619 - val_loss: 0.0649 - val_mae: 0.0649 - val_mse: 0.0267 - val_accuracy: 0.9608\n",
      "[14:56:06][epoch 1/3 | file 18/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[14:56:08][epoch 1/3 | file 19/19] Loading and preparing \"blured12to1_withHud_25k__17of19__2021-02-02 13-36-39.npy\"...\n",
      "[14:56:30][epoch 1/3 | file 19/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 28s - loss: 0.0711 - mae: 0.0711 - mse: 0.0341 - accuracy: 0.9531WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0359s vs `on_train_batch_end` time: 0.0628s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0723 - mae: 0.0723 - mse: 0.0348 - accuracy: 0.9320 - val_loss: 0.0740 - val_mae: 0.0740 - val_mse: 0.0367 - val_accuracy: 0.9292\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 98ms/step - loss: 0.0723 - mae: 0.0723 - mse: 0.0348 - accuracy: 0.9320 - val_loss: 0.0740 - val_mae: 0.0740 - val_mse: 0.0367 - val_accuracy: 0.9292\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0723 - mae: 0.0723 - mse: 0.0348 - accuracy: 0.9320 - val_loss: 0.0740 - val_mae: 0.0740 - val_mse: 0.0367 - val_accuracy: 0.9292\n",
      "[14:58:15][epoch 1/3 | file 19/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "\n",
      "[14:58:17] Epoch 2 of 3 is starting...\n",
      "\n",
      "[14:58:17][epoch 2/3 | file 1/19] Loading and preparing \"blured12to1_withHud_25k__19of19__2021-02-02 13-39-03.npy\"...\n",
      "[14:58:21][epoch 2/3 | file 1/19] Training model...\n",
      "Epoch 1/3\n",
      " 2/71 [..............................] - ETA: 5s - loss: 0.0749 - mae: 0.0749 - mse: 0.0352 - accuracy: 0.9297WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0349s vs `on_train_batch_end` time: 0.0618s). Check your callbacks.\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 0.0687 - mae: 0.0687 - mse: 0.0298 - accuracy: 0.9458 - val_loss: 0.0715 - val_mae: 0.0715 - val_mse: 0.0323 - val_accuracy: 0.9400\n",
      "Epoch 2/3\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 0.0687 - mae: 0.0687 - mse: 0.0298 - accuracy: 0.9458 - val_loss: 0.0715 - val_mae: 0.0715 - val_mse: 0.0323 - val_accuracy: 0.9400\n",
      "Epoch 3/3\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 0.0687 - mae: 0.0687 - mse: 0.0298 - accuracy: 0.9458 - val_loss: 0.0715 - val_mae: 0.0715 - val_mse: 0.0323 - val_accuracy: 0.9400\n",
      "[14:58:42][epoch 2/3 | file 1/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[14:58:43][epoch 2/3 | file 2/19] Loading and preparing \"blured12to1_withHud_25k__6of19__2021-02-02 13-29-27.npy\"...\n",
      "[14:59:05][epoch 2/3 | file 2/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 27s - loss: 0.1102 - mae: 0.1102 - mse: 0.0749 - accuracy: 0.7734WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0349s vs `on_train_batch_end` time: 0.0608s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.1001 - mae: 0.1001 - mse: 0.0623 - accuracy: 0.8337 - val_loss: 0.1032 - val_mae: 0.1032 - val_mse: 0.0652 - val_accuracy: 0.8236\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.1001 - mae: 0.1001 - mse: 0.0623 - accuracy: 0.8337 - val_loss: 0.1032 - val_mae: 0.1032 - val_mse: 0.0652 - val_accuracy: 0.8236\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.1001 - mae: 0.1001 - mse: 0.0623 - accuracy: 0.8337 - val_loss: 0.1032 - val_mae: 0.1032 - val_mse: 0.0652 - val_accuracy: 0.8236\n",
      "[15:00:51][epoch 2/3 | file 2/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[15:00:52][epoch 2/3 | file 3/19] Loading and preparing \"blured12to1_withHud_25k__12of19__2021-02-02 13-31-58.npy\"...\n",
      "[15:01:15][epoch 2/3 | file 3/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 28s - loss: 0.0675 - mae: 0.0675 - mse: 0.0278 - accuracy: 0.9766WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0359s vs `on_train_batch_end` time: 0.0618s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0626 - mae: 0.0626 - mse: 0.0240 - accuracy: 0.9703 - val_loss: 0.0641 - val_mae: 0.0641 - val_mse: 0.0250 - val_accuracy: 0.9664\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0626 - mae: 0.0626 - mse: 0.0240 - accuracy: 0.9703 - val_loss: 0.0641 - val_mae: 0.0641 - val_mse: 0.0250 - val_accuracy: 0.9664\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0626 - mae: 0.0626 - mse: 0.0240 - accuracy: 0.9703 - val_loss: 0.0641 - val_mae: 0.0641 - val_mse: 0.0250 - val_accuracy: 0.9664\n",
      "[15:03:00][epoch 2/3 | file 3/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[15:03:02][epoch 2/3 | file 4/19] Loading and preparing \"blured12to1_withHud_25k__9of19__2021-02-02 13-30-44.npy\"...\n",
      "[15:03:24][epoch 2/3 | file 4/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 27s - loss: 0.0647 - mae: 0.0647 - mse: 0.0295 - accuracy: 0.9531WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0349s vs `on_train_batch_end` time: 0.0628s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0658 - mae: 0.0658 - mse: 0.0282 - accuracy: 0.9601 - val_loss: 0.0648 - val_mae: 0.0648 - val_mse: 0.0275 - val_accuracy: 0.9628\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0658 - mae: 0.0658 - mse: 0.0282 - accuracy: 0.9601 - val_loss: 0.0648 - val_mae: 0.0648 - val_mse: 0.0275 - val_accuracy: 0.9628\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 100ms/step - loss: 0.0658 - mae: 0.0658 - mse: 0.0282 - accuracy: 0.9601 - val_loss: 0.0648 - val_mae: 0.0648 - val_mse: 0.0275 - val_accuracy: 0.9628\n",
      "[15:05:10][epoch 2/3 | file 4/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[15:05:11][epoch 2/3 | file 5/19] Loading and preparing \"blured12to1_withHud_25k__10of19__2021-02-02 13-31-10.npy\"...\n",
      "[15:05:34][epoch 2/3 | file 5/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 27s - loss: 0.0680 - mae: 0.0680 - mse: 0.0305 - accuracy: 0.9219WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0354s vs `on_train_batch_end` time: 0.0608s). Check your callbacks.\n",
      "352/352 [==============================] - 35s 98ms/step - loss: 0.0752 - mae: 0.0752 - mse: 0.0387 - accuracy: 0.9119 - val_loss: 0.0758 - val_mae: 0.0758 - val_mse: 0.0389 - val_accuracy: 0.9112\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0752 - mae: 0.0752 - mse: 0.0387 - accuracy: 0.9119 - val_loss: 0.0758 - val_mae: 0.0758 - val_mse: 0.0389 - val_accuracy: 0.9112\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0752 - mae: 0.0752 - mse: 0.0387 - accuracy: 0.9119 - val_loss: 0.0758 - val_mae: 0.0758 - val_mse: 0.0389 - val_accuracy: 0.9112\n",
      "[15:07:20][epoch 2/3 | file 5/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[15:07:21][epoch 2/3 | file 6/19] Loading and preparing \"blured12to1_withHud_25k__18of19__2021-02-02 13-37-51.npy\"...\n",
      "[15:07:44][epoch 2/3 | file 6/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 27s - loss: 0.0513 - mae: 0.0513 - mse: 0.0208 - accuracy: 0.9688WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0349s vs `on_train_batch_end` time: 0.0618s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0670 - mae: 0.0670 - mse: 0.0294 - accuracy: 0.9487 - val_loss: 0.0669 - val_mae: 0.0669 - val_mse: 0.0298 - val_accuracy: 0.9452\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0670 - mae: 0.0670 - mse: 0.0294 - accuracy: 0.9487 - val_loss: 0.0669 - val_mae: 0.0669 - val_mse: 0.0298 - val_accuracy: 0.9452\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0670 - mae: 0.0670 - mse: 0.0294 - accuracy: 0.9487 - val_loss: 0.0669 - val_mae: 0.0669 - val_mse: 0.0298 - val_accuracy: 0.9452\n",
      "[15:09:29][epoch 2/3 | file 6/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[15:09:31][epoch 2/3 | file 7/19] Loading and preparing \"blured12to1_withHud_25k__4of19__2021-02-02 13-27-15.npy\"...\n",
      "[15:09:53][epoch 2/3 | file 7/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 28s - loss: 0.0568 - mae: 0.0568 - mse: 0.0213 - accuracy: 0.9766WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0354s vs `on_train_batch_end` time: 0.0618s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0627 - mae: 0.0627 - mse: 0.0257 - accuracy: 0.9586 - val_loss: 0.0636 - val_mae: 0.0636 - val_mse: 0.0261 - val_accuracy: 0.9596\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 98ms/step - loss: 0.0627 - mae: 0.0627 - mse: 0.0257 - accuracy: 0.9586 - val_loss: 0.0636 - val_mae: 0.0636 - val_mse: 0.0261 - val_accuracy: 0.9596\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0627 - mae: 0.0627 - mse: 0.0257 - accuracy: 0.9586 - val_loss: 0.0636 - val_mae: 0.0636 - val_mse: 0.0261 - val_accuracy: 0.9596\n",
      "[15:11:38][epoch 2/3 | file 7/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[15:11:40][epoch 2/3 | file 8/19] Loading and preparing \"blured12to1_withHud_25k__3of19__2021-02-02 13-26-18.npy\"...\n",
      "[15:12:02][epoch 2/3 | file 8/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 27s - loss: 0.0576 - mae: 0.0576 - mse: 0.0211 - accuracy: 0.9688WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0359s vs `on_train_batch_end` time: 0.0628s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0646 - mae: 0.0646 - mse: 0.0293 - accuracy: 0.9411 - val_loss: 0.0654 - val_mae: 0.0654 - val_mse: 0.0298 - val_accuracy: 0.9444\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 98ms/step - loss: 0.0646 - mae: 0.0646 - mse: 0.0293 - accuracy: 0.9411 - val_loss: 0.0654 - val_mae: 0.0654 - val_mse: 0.0298 - val_accuracy: 0.9444\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0646 - mae: 0.0646 - mse: 0.0293 - accuracy: 0.9411 - val_loss: 0.0654 - val_mae: 0.0654 - val_mse: 0.0298 - val_accuracy: 0.9444\n",
      "[15:13:47][epoch 2/3 | file 8/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[15:13:48][epoch 2/3 | file 9/19] Loading and preparing \"blured12to1_withHud_25k__17of19__2021-02-02 13-36-39.npy\"...\n",
      "[15:14:10][epoch 2/3 | file 9/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 28s - loss: 0.0706 - mae: 0.0706 - mse: 0.0345 - accuracy: 0.9297WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0359s vs `on_train_batch_end` time: 0.0628s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0724 - mae: 0.0724 - mse: 0.0349 - accuracy: 0.9323 - val_loss: 0.0731 - val_mae: 0.0731 - val_mse: 0.0355 - val_accuracy: 0.9272\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0724 - mae: 0.0724 - mse: 0.0349 - accuracy: 0.9323 - val_loss: 0.0731 - val_mae: 0.0731 - val_mse: 0.0355 - val_accuracy: 0.9272\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0724 - mae: 0.0724 - mse: 0.0349 - accuracy: 0.9323 - val_loss: 0.0731 - val_mae: 0.0731 - val_mse: 0.0355 - val_accuracy: 0.9272\n",
      "[15:15:56][epoch 2/3 | file 9/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[15:15:58][epoch 2/3 | file 10/19] Loading and preparing \"blured12to1_withHud_25k__5of19__2021-02-02 13-28-22.npy\"...\n",
      "[15:16:20][epoch 2/3 | file 10/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 28s - loss: 0.0665 - mae: 0.0665 - mse: 0.0260 - accuracy: 0.9609WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0359s vs `on_train_batch_end` time: 0.0628s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0577 - mae: 0.0577 - mse: 0.0208 - accuracy: 0.9774 - val_loss: 0.0571 - val_mae: 0.0571 - val_mse: 0.0199 - val_accuracy: 0.9784\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0577 - mae: 0.0577 - mse: 0.0208 - accuracy: 0.9774 - val_loss: 0.0571 - val_mae: 0.0571 - val_mse: 0.0199 - val_accuracy: 0.9784\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0577 - mae: 0.0577 - mse: 0.0208 - accuracy: 0.9774 - val_loss: 0.0571 - val_mae: 0.0571 - val_mse: 0.0199 - val_accuracy: 0.9784\n",
      "[15:18:05][epoch 2/3 | file 10/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[15:18:07][epoch 2/3 | file 11/19] Loading and preparing \"blured12to1_withHud_25k__1of19__2021-02-02 13-25-30.npy\"...\n",
      "[15:18:30][epoch 2/3 | file 11/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 28s - loss: 0.0634 - mae: 0.0634 - mse: 0.0289 - accuracy: 0.9609WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0354s vs `on_train_batch_end` time: 0.0628s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0666 - mae: 0.0666 - mse: 0.0307 - accuracy: 0.9419 - val_loss: 0.0652 - val_mae: 0.0652 - val_mse: 0.0298 - val_accuracy: 0.9448\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0666 - mae: 0.0666 - mse: 0.0307 - accuracy: 0.9419 - val_loss: 0.0652 - val_mae: 0.0652 - val_mse: 0.0298 - val_accuracy: 0.9448\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0666 - mae: 0.0666 - mse: 0.0307 - accuracy: 0.9419 - val_loss: 0.0652 - val_mae: 0.0652 - val_mse: 0.0298 - val_accuracy: 0.9448\n",
      "[15:20:15][epoch 2/3 | file 11/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[15:20:17][epoch 2/3 | file 12/19] Loading and preparing \"blured12to1_withHud_25k__11of19__2021-02-02 13-31-35.npy\"...\n",
      "[15:20:40][epoch 2/3 | file 12/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 28s - loss: 0.0563 - mae: 0.0563 - mse: 0.0238 - accuracy: 0.9688WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0349s vs `on_train_batch_end` time: 0.0638s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0604 - mae: 0.0604 - mse: 0.0237 - accuracy: 0.9732 - val_loss: 0.0595 - val_mae: 0.0595 - val_mse: 0.0234 - val_accuracy: 0.9744\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0604 - mae: 0.0604 - mse: 0.0237 - accuracy: 0.9732 - val_loss: 0.0595 - val_mae: 0.0595 - val_mse: 0.0234 - val_accuracy: 0.9744\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 100ms/step - loss: 0.0604 - mae: 0.0604 - mse: 0.0237 - accuracy: 0.9732 - val_loss: 0.0595 - val_mae: 0.0595 - val_mse: 0.0234 - val_accuracy: 0.9744\n",
      "[15:22:25][epoch 2/3 | file 12/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[15:22:26][epoch 2/3 | file 13/19] Loading and preparing \"blured12to1_withHud_25k__2of19__2021-02-02 13-25-54.npy\"...\n",
      "[15:22:49][epoch 2/3 | file 13/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 28s - loss: 0.0719 - mae: 0.0719 - mse: 0.0394 - accuracy: 0.9219WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0359s vs `on_train_batch_end` time: 0.0608s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0721 - mae: 0.0721 - mse: 0.0358 - accuracy: 0.9252 - val_loss: 0.0757 - val_mae: 0.0757 - val_mse: 0.0387 - val_accuracy: 0.9220\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0721 - mae: 0.0721 - mse: 0.0358 - accuracy: 0.9252 - val_loss: 0.0757 - val_mae: 0.0757 - val_mse: 0.0387 - val_accuracy: 0.9220\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0721 - mae: 0.0721 - mse: 0.0358 - accuracy: 0.9252 - val_loss: 0.0757 - val_mae: 0.0757 - val_mse: 0.0387 - val_accuracy: 0.9220\n",
      "[15:24:34][epoch 2/3 | file 13/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[15:24:35][epoch 2/3 | file 14/19] Loading and preparing \"blured12to1_withHud_25k__7of19__2021-02-02 13-29-54.npy\"...\n",
      "[15:24:58][epoch 2/3 | file 14/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 28s - loss: 0.0645 - mae: 0.0645 - mse: 0.0309 - accuracy: 0.9375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0349s vs `on_train_batch_end` time: 0.0638s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0712 - mae: 0.0712 - mse: 0.0351 - accuracy: 0.9300 - val_loss: 0.0699 - val_mae: 0.0699 - val_mse: 0.0342 - val_accuracy: 0.9348\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 98ms/step - loss: 0.0712 - mae: 0.0712 - mse: 0.0351 - accuracy: 0.9300 - val_loss: 0.0699 - val_mae: 0.0699 - val_mse: 0.0342 - val_accuracy: 0.9348\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0712 - mae: 0.0712 - mse: 0.0351 - accuracy: 0.9300 - val_loss: 0.0699 - val_mae: 0.0699 - val_mse: 0.0342 - val_accuracy: 0.9348\n",
      "[15:26:43][epoch 2/3 | file 14/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[15:26:45][epoch 2/3 | file 15/19] Loading and preparing \"blured12to1_withHud_25k__8of19__2021-02-02 13-30-21.npy\"...\n",
      "[15:27:07][epoch 2/3 | file 15/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 27s - loss: 0.0570 - mae: 0.0570 - mse: 0.0227 - accuracy: 0.9766WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0349s vs `on_train_batch_end` time: 0.0608s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0638 - mae: 0.0638 - mse: 0.0260 - accuracy: 0.9616 - val_loss: 0.0634 - val_mae: 0.0634 - val_mse: 0.0253 - val_accuracy: 0.9640\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 98ms/step - loss: 0.0638 - mae: 0.0638 - mse: 0.0260 - accuracy: 0.9616 - val_loss: 0.0634 - val_mae: 0.0634 - val_mse: 0.0253 - val_accuracy: 0.9640\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0638 - mae: 0.0638 - mse: 0.0260 - accuracy: 0.9616 - val_loss: 0.0634 - val_mae: 0.0634 - val_mse: 0.0253 - val_accuracy: 0.9640\n",
      "[15:28:52][epoch 2/3 | file 15/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[15:28:54][epoch 2/3 | file 16/19] Loading and preparing \"blured12to1_withHud_25k__13of19__2021-02-02 13-32-25.npy\"...\n",
      "[15:29:16][epoch 2/3 | file 16/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 27s - loss: 0.0679 - mae: 0.0679 - mse: 0.0286 - accuracy: 0.9609WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0349s vs `on_train_batch_end` time: 0.0628s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0573 - mae: 0.0573 - mse: 0.0214 - accuracy: 0.9744 - val_loss: 0.0580 - val_mae: 0.0580 - val_mse: 0.0216 - val_accuracy: 0.9748\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 98ms/step - loss: 0.0573 - mae: 0.0573 - mse: 0.0214 - accuracy: 0.9744 - val_loss: 0.0580 - val_mae: 0.0580 - val_mse: 0.0216 - val_accuracy: 0.9748\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0573 - mae: 0.0573 - mse: 0.0214 - accuracy: 0.9744 - val_loss: 0.0580 - val_mae: 0.0580 - val_mse: 0.0216 - val_accuracy: 0.9748\n",
      "[15:31:01][epoch 2/3 | file 16/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[15:31:03][epoch 2/3 | file 17/19] Loading and preparing \"blured12to1_withHud_25k__16of19__2021-02-02 13-35-25.npy\"...\n",
      "[15:31:25][epoch 2/3 | file 17/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 28s - loss: 0.0677 - mae: 0.0677 - mse: 0.0326 - accuracy: 0.9453WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0349s vs `on_train_batch_end` time: 0.0628s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0717 - mae: 0.0717 - mse: 0.0348 - accuracy: 0.9336 - val_loss: 0.0704 - val_mae: 0.0704 - val_mse: 0.0347 - val_accuracy: 0.9316\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 98ms/step - loss: 0.0717 - mae: 0.0717 - mse: 0.0348 - accuracy: 0.9336 - val_loss: 0.0704 - val_mae: 0.0704 - val_mse: 0.0347 - val_accuracy: 0.9316\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0717 - mae: 0.0717 - mse: 0.0348 - accuracy: 0.9336 - val_loss: 0.0704 - val_mae: 0.0704 - val_mse: 0.0347 - val_accuracy: 0.9316\n",
      "[15:33:10][epoch 2/3 | file 17/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[15:33:11][epoch 2/3 | file 18/19] Loading and preparing \"blured12to1_withHud_25k__15of19__2021-02-02 13-34-09.npy\"...\n",
      "[15:33:33][epoch 2/3 | file 18/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 27s - loss: 0.0580 - mae: 0.0580 - mse: 0.0227 - accuracy: 0.9609WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0349s vs `on_train_batch_end` time: 0.0608s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0572 - mae: 0.0572 - mse: 0.0221 - accuracy: 0.9735 - val_loss: 0.0576 - val_mae: 0.0576 - val_mse: 0.0227 - val_accuracy: 0.9736\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0572 - mae: 0.0572 - mse: 0.0221 - accuracy: 0.9735 - val_loss: 0.0576 - val_mae: 0.0576 - val_mse: 0.0227 - val_accuracy: 0.9736\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0572 - mae: 0.0572 - mse: 0.0221 - accuracy: 0.9735 - val_loss: 0.0576 - val_mae: 0.0576 - val_mse: 0.0227 - val_accuracy: 0.9736\n",
      "[15:35:19][epoch 2/3 | file 18/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[15:35:20][epoch 2/3 | file 19/19] Loading and preparing \"blured12to1_withHud_25k__14of19__2021-02-02 13-32-59.npy\"...\n",
      "[15:35:42][epoch 2/3 | file 19/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 28s - loss: 0.0685 - mae: 0.0685 - mse: 0.0324 - accuracy: 0.9375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0349s vs `on_train_batch_end` time: 0.0628s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0674 - mae: 0.0674 - mse: 0.0312 - accuracy: 0.9424 - val_loss: 0.0665 - val_mae: 0.0665 - val_mse: 0.0306 - val_accuracy: 0.9440\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 98ms/step - loss: 0.0674 - mae: 0.0674 - mse: 0.0312 - accuracy: 0.9424 - val_loss: 0.0665 - val_mae: 0.0665 - val_mse: 0.0306 - val_accuracy: 0.9440\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0674 - mae: 0.0674 - mse: 0.0312 - accuracy: 0.9424 - val_loss: 0.0665 - val_mae: 0.0665 - val_mse: 0.0306 - val_accuracy: 0.9440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:37:27][epoch 2/3 | file 19/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "\n",
      "[15:37:29] Epoch 3 of 3 is starting...\n",
      "\n",
      "[15:37:29][epoch 3/3 | file 1/19] Loading and preparing \"blured12to1_withHud_25k__14of19__2021-02-02 13-32-59.npy\"...\n",
      "[15:37:45][epoch 3/3 | file 1/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 28s - loss: 0.0676 - mae: 0.0676 - mse: 0.0296 - accuracy: 0.9531WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0354s vs `on_train_batch_end` time: 0.0628s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0672 - mae: 0.0672 - mse: 0.0310 - accuracy: 0.9430 - val_loss: 0.0689 - val_mae: 0.0689 - val_mse: 0.0326 - val_accuracy: 0.9388\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0672 - mae: 0.0672 - mse: 0.0310 - accuracy: 0.9430 - val_loss: 0.0689 - val_mae: 0.0689 - val_mse: 0.0326 - val_accuracy: 0.9388\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0672 - mae: 0.0672 - mse: 0.0310 - accuracy: 0.9430 - val_loss: 0.0689 - val_mae: 0.0689 - val_mse: 0.0326 - val_accuracy: 0.9388\n",
      "[15:39:30][epoch 3/3 | file 1/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[15:39:32][epoch 3/3 | file 2/19] Loading and preparing \"blured12to1_withHud_25k__12of19__2021-02-02 13-31-58.npy\"...\n",
      "[15:39:54][epoch 3/3 | file 2/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 27s - loss: 0.0702 - mae: 0.0702 - mse: 0.0291 - accuracy: 0.9531WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0349s vs `on_train_batch_end` time: 0.0618s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0629 - mae: 0.0629 - mse: 0.0242 - accuracy: 0.9696 - val_loss: 0.0612 - val_mae: 0.0612 - val_mse: 0.0233 - val_accuracy: 0.9720\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 98ms/step - loss: 0.0629 - mae: 0.0629 - mse: 0.0242 - accuracy: 0.9696 - val_loss: 0.0612 - val_mae: 0.0612 - val_mse: 0.0233 - val_accuracy: 0.9720\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0629 - mae: 0.0629 - mse: 0.0242 - accuracy: 0.9696 - val_loss: 0.0612 - val_mae: 0.0612 - val_mse: 0.0233 - val_accuracy: 0.9720\n",
      "[15:41:39][epoch 3/3 | file 2/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[15:41:40][epoch 3/3 | file 3/19] Loading and preparing \"blured12to1_withHud_25k__5of19__2021-02-02 13-28-22.npy\"...\n",
      "[15:42:03][epoch 3/3 | file 3/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 28s - loss: 0.0587 - mae: 0.0587 - mse: 0.0189 - accuracy: 0.9922WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0349s vs `on_train_batch_end` time: 0.0638s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0578 - mae: 0.0578 - mse: 0.0207 - accuracy: 0.9776 - val_loss: 0.0568 - val_mae: 0.0568 - val_mse: 0.0203 - val_accuracy: 0.9768\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0578 - mae: 0.0578 - mse: 0.0207 - accuracy: 0.9776 - val_loss: 0.0568 - val_mae: 0.0568 - val_mse: 0.0203 - val_accuracy: 0.9768\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0578 - mae: 0.0578 - mse: 0.0207 - accuracy: 0.9776 - val_loss: 0.0568 - val_mae: 0.0568 - val_mse: 0.0203 - val_accuracy: 0.9768\n",
      "[15:43:48][epoch 3/3 | file 3/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[15:43:50][epoch 3/3 | file 4/19] Loading and preparing \"blured12to1_withHud_25k__18of19__2021-02-02 13-37-51.npy\"...\n",
      "[15:44:12][epoch 3/3 | file 4/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 27s - loss: 0.0706 - mae: 0.0706 - mse: 0.0308 - accuracy: 0.9375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0349s vs `on_train_batch_end` time: 0.0628s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0671 - mae: 0.0671 - mse: 0.0296 - accuracy: 0.9478 - val_loss: 0.0654 - val_mae: 0.0654 - val_mse: 0.0279 - val_accuracy: 0.9528\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0671 - mae: 0.0671 - mse: 0.0296 - accuracy: 0.9478 - val_loss: 0.0654 - val_mae: 0.0654 - val_mse: 0.0279 - val_accuracy: 0.9528\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0671 - mae: 0.0671 - mse: 0.0296 - accuracy: 0.9478 - val_loss: 0.0654 - val_mae: 0.0654 - val_mse: 0.0279 - val_accuracy: 0.9528\n",
      "[15:45:57][epoch 3/3 | file 4/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[15:45:58][epoch 3/3 | file 5/19] Loading and preparing \"blured12to1_withHud_25k__15of19__2021-02-02 13-34-09.npy\"...\n",
      "[15:46:15][epoch 3/3 | file 5/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 27s - loss: 0.0511 - mae: 0.0511 - mse: 0.0206 - accuracy: 0.9688WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0339s vs `on_train_batch_end` time: 0.0618s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0570 - mae: 0.0570 - mse: 0.0221 - accuracy: 0.9737 - val_loss: 0.0590 - val_mae: 0.0590 - val_mse: 0.0230 - val_accuracy: 0.9720\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0570 - mae: 0.0570 - mse: 0.0221 - accuracy: 0.9737 - val_loss: 0.0590 - val_mae: 0.0590 - val_mse: 0.0230 - val_accuracy: 0.9720\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0570 - mae: 0.0570 - mse: 0.0221 - accuracy: 0.9737 - val_loss: 0.0590 - val_mae: 0.0590 - val_mse: 0.0230 - val_accuracy: 0.9720\n",
      "[15:48:00][epoch 3/3 | file 5/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[15:48:02][epoch 3/3 | file 6/19] Loading and preparing \"blured12to1_withHud_25k__2of19__2021-02-02 13-25-54.npy\"...\n",
      "[15:48:24][epoch 3/3 | file 6/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 27s - loss: 0.0645 - mae: 0.0645 - mse: 0.0318 - accuracy: 0.9219WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0339s vs `on_train_batch_end` time: 0.0618s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0723 - mae: 0.0723 - mse: 0.0359 - accuracy: 0.9253 - val_loss: 0.0742 - val_mae: 0.0742 - val_mse: 0.0374 - val_accuracy: 0.9216\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0723 - mae: 0.0723 - mse: 0.0359 - accuracy: 0.9253 - val_loss: 0.0742 - val_mae: 0.0742 - val_mse: 0.0374 - val_accuracy: 0.9216\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0723 - mae: 0.0723 - mse: 0.0359 - accuracy: 0.9253 - val_loss: 0.0742 - val_mae: 0.0742 - val_mse: 0.0374 - val_accuracy: 0.9216\n",
      "[15:50:09][epoch 3/3 | file 6/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[15:50:11][epoch 3/3 | file 7/19] Loading and preparing \"blured12to1_withHud_25k__3of19__2021-02-02 13-26-18.npy\"...\n",
      "[15:50:33][epoch 3/3 | file 7/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 27s - loss: 0.0553 - mae: 0.0553 - mse: 0.0229 - accuracy: 0.9453WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0339s vs `on_train_batch_end` time: 0.0608s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0649 - mae: 0.0649 - mse: 0.0295 - accuracy: 0.9411 - val_loss: 0.0632 - val_mae: 0.0632 - val_mse: 0.0279 - val_accuracy: 0.9444\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 98ms/step - loss: 0.0649 - mae: 0.0649 - mse: 0.0295 - accuracy: 0.9411 - val_loss: 0.0632 - val_mae: 0.0632 - val_mse: 0.0279 - val_accuracy: 0.9444\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0649 - mae: 0.0649 - mse: 0.0295 - accuracy: 0.9411 - val_loss: 0.0632 - val_mae: 0.0632 - val_mse: 0.0279 - val_accuracy: 0.9444\n",
      "[15:52:18][epoch 3/3 | file 7/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[15:52:20][epoch 3/3 | file 8/19] Loading and preparing \"blured12to1_withHud_25k__13of19__2021-02-02 13-32-25.npy\"...\n",
      "[15:52:42][epoch 3/3 | file 8/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 27s - loss: 0.0594 - mae: 0.0594 - mse: 0.0226 - accuracy: 0.9688WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0349s vs `on_train_batch_end` time: 0.0623s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0574 - mae: 0.0574 - mse: 0.0215 - accuracy: 0.9745 - val_loss: 0.0571 - val_mae: 0.0571 - val_mse: 0.0212 - val_accuracy: 0.9740\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 98ms/step - loss: 0.0574 - mae: 0.0574 - mse: 0.0215 - accuracy: 0.9745 - val_loss: 0.0571 - val_mae: 0.0571 - val_mse: 0.0212 - val_accuracy: 0.9740\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0574 - mae: 0.0574 - mse: 0.0215 - accuracy: 0.9745 - val_loss: 0.0571 - val_mae: 0.0571 - val_mse: 0.0212 - val_accuracy: 0.9740\n",
      "[15:54:27][epoch 3/3 | file 8/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[15:54:28][epoch 3/3 | file 9/19] Loading and preparing \"blured12to1_withHud_25k__17of19__2021-02-02 13-36-39.npy\"...\n",
      "[15:54:50][epoch 3/3 | file 9/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 28s - loss: 0.0720 - mae: 0.0720 - mse: 0.0362 - accuracy: 0.9297WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0349s vs `on_train_batch_end` time: 0.0638s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0726 - mae: 0.0726 - mse: 0.0351 - accuracy: 0.9313 - val_loss: 0.0709 - val_mae: 0.0709 - val_mse: 0.0335 - val_accuracy: 0.9360\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 98ms/step - loss: 0.0726 - mae: 0.0726 - mse: 0.0351 - accuracy: 0.9313 - val_loss: 0.0709 - val_mae: 0.0709 - val_mse: 0.0335 - val_accuracy: 0.9360\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0726 - mae: 0.0726 - mse: 0.0351 - accuracy: 0.9313 - val_loss: 0.0709 - val_mae: 0.0709 - val_mse: 0.0335 - val_accuracy: 0.9360\n",
      "[15:56:35][epoch 3/3 | file 9/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[15:56:37][epoch 3/3 | file 10/19] Loading and preparing \"blured12to1_withHud_25k__6of19__2021-02-02 13-29-27.npy\"...\n",
      "[15:57:00][epoch 3/3 | file 10/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 28s - loss: 0.1046 - mae: 0.1046 - mse: 0.0693 - accuracy: 0.8125WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0359s vs `on_train_batch_end` time: 0.0628s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.1000 - mae: 0.1000 - mse: 0.0623 - accuracy: 0.8334 - val_loss: 0.1039 - val_mae: 0.1039 - val_mse: 0.0659 - val_accuracy: 0.8260\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 98ms/step - loss: 0.1000 - mae: 0.1000 - mse: 0.0623 - accuracy: 0.8334 - val_loss: 0.1039 - val_mae: 0.1039 - val_mse: 0.0659 - val_accuracy: 0.8260\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.1000 - mae: 0.1000 - mse: 0.0623 - accuracy: 0.8334 - val_loss: 0.1039 - val_mae: 0.1039 - val_mse: 0.0659 - val_accuracy: 0.8260\n",
      "[15:58:44][epoch 3/3 | file 10/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[15:58:46][epoch 3/3 | file 11/19] Loading and preparing \"blured12to1_withHud_25k__10of19__2021-02-02 13-31-10.npy\"...\n",
      "[15:59:08][epoch 3/3 | file 11/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 28s - loss: 0.0777 - mae: 0.0777 - mse: 0.0397 - accuracy: 0.9297WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0359s vs `on_train_batch_end` time: 0.0648s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0751 - mae: 0.0751 - mse: 0.0386 - accuracy: 0.9125 - val_loss: 0.0761 - val_mae: 0.0761 - val_mse: 0.0398 - val_accuracy: 0.9060\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 98ms/step - loss: 0.0751 - mae: 0.0751 - mse: 0.0386 - accuracy: 0.9125 - val_loss: 0.0761 - val_mae: 0.0761 - val_mse: 0.0398 - val_accuracy: 0.9060\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0751 - mae: 0.0751 - mse: 0.0386 - accuracy: 0.9125 - val_loss: 0.0761 - val_mae: 0.0761 - val_mse: 0.0398 - val_accuracy: 0.9060\n",
      "[16:00:54][epoch 3/3 | file 11/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[16:00:55][epoch 3/3 | file 12/19] Loading and preparing \"blured12to1_withHud_25k__1of19__2021-02-02 13-25-30.npy\"...\n",
      "[16:01:18][epoch 3/3 | file 12/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 28s - loss: 0.0663 - mae: 0.0663 - mse: 0.0293 - accuracy: 0.9531WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0359s vs `on_train_batch_end` time: 0.0628s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0663 - mae: 0.0663 - mse: 0.0304 - accuracy: 0.9428 - val_loss: 0.0675 - val_mae: 0.0675 - val_mse: 0.0320 - val_accuracy: 0.9368\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0663 - mae: 0.0663 - mse: 0.0304 - accuracy: 0.9428 - val_loss: 0.0675 - val_mae: 0.0675 - val_mse: 0.0320 - val_accuracy: 0.9368\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0663 - mae: 0.0663 - mse: 0.0304 - accuracy: 0.9428 - val_loss: 0.0675 - val_mae: 0.0675 - val_mse: 0.0320 - val_accuracy: 0.9368\n",
      "[16:03:03][epoch 3/3 | file 12/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[16:03:04][epoch 3/3 | file 13/19] Loading and preparing \"blured12to1_withHud_25k__8of19__2021-02-02 13-30-21.npy\"...\n",
      "[16:03:27][epoch 3/3 | file 13/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 27s - loss: 0.0629 - mae: 0.0629 - mse: 0.0226 - accuracy: 0.9844WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0354s vs `on_train_batch_end` time: 0.0628s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0639 - mae: 0.0639 - mse: 0.0260 - accuracy: 0.9615 - val_loss: 0.0623 - val_mae: 0.0623 - val_mse: 0.0249 - val_accuracy: 0.9648\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 98ms/step - loss: 0.0639 - mae: 0.0639 - mse: 0.0260 - accuracy: 0.9615 - val_loss: 0.0623 - val_mae: 0.0623 - val_mse: 0.0249 - val_accuracy: 0.9648\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0639 - mae: 0.0639 - mse: 0.0260 - accuracy: 0.9615 - val_loss: 0.0623 - val_mae: 0.0623 - val_mse: 0.0249 - val_accuracy: 0.9648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:05:12][epoch 3/3 | file 13/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[16:05:13][epoch 3/3 | file 14/19] Loading and preparing \"blured12to1_withHud_25k__4of19__2021-02-02 13-27-15.npy\"...\n",
      "[16:05:36][epoch 3/3 | file 14/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 27s - loss: 0.0688 - mae: 0.0688 - mse: 0.0325 - accuracy: 0.9375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0339s vs `on_train_batch_end` time: 0.0598s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0629 - mae: 0.0629 - mse: 0.0259 - accuracy: 0.9584 - val_loss: 0.0611 - val_mae: 0.0611 - val_mse: 0.0250 - val_accuracy: 0.9612\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0629 - mae: 0.0629 - mse: 0.0259 - accuracy: 0.9584 - val_loss: 0.0611 - val_mae: 0.0611 - val_mse: 0.0250 - val_accuracy: 0.9612\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0629 - mae: 0.0629 - mse: 0.0259 - accuracy: 0.9584 - val_loss: 0.0611 - val_mae: 0.0611 - val_mse: 0.0250 - val_accuracy: 0.9612\n",
      "[16:07:22][epoch 3/3 | file 14/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[16:07:23][epoch 3/3 | file 15/19] Loading and preparing \"blured12to1_withHud_25k__7of19__2021-02-02 13-29-54.npy\"...\n",
      "[16:07:46][epoch 3/3 | file 15/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 27s - loss: 0.0725 - mae: 0.0725 - mse: 0.0366 - accuracy: 0.9375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0349s vs `on_train_batch_end` time: 0.0628s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0713 - mae: 0.0713 - mse: 0.0353 - accuracy: 0.9296 - val_loss: 0.0685 - val_mae: 0.0685 - val_mse: 0.0324 - val_accuracy: 0.9376\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 98ms/step - loss: 0.0713 - mae: 0.0713 - mse: 0.0353 - accuracy: 0.9296 - val_loss: 0.0685 - val_mae: 0.0685 - val_mse: 0.0324 - val_accuracy: 0.9376\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0713 - mae: 0.0713 - mse: 0.0353 - accuracy: 0.9296 - val_loss: 0.0685 - val_mae: 0.0685 - val_mse: 0.0324 - val_accuracy: 0.9376\n",
      "[16:09:31][epoch 3/3 | file 15/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[16:09:32][epoch 3/3 | file 16/19] Loading and preparing \"blured12to1_withHud_25k__9of19__2021-02-02 13-30-44.npy\"...\n",
      "[16:09:55][epoch 3/3 | file 16/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 27s - loss: 0.0753 - mae: 0.0753 - mse: 0.0308 - accuracy: 0.9688WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0349s vs `on_train_batch_end` time: 0.0608s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0659 - mae: 0.0659 - mse: 0.0283 - accuracy: 0.9596 - val_loss: 0.0642 - val_mae: 0.0642 - val_mse: 0.0267 - val_accuracy: 0.9668\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0659 - mae: 0.0659 - mse: 0.0283 - accuracy: 0.9596 - val_loss: 0.0642 - val_mae: 0.0642 - val_mse: 0.0267 - val_accuracy: 0.9668\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0659 - mae: 0.0659 - mse: 0.0283 - accuracy: 0.9596 - val_loss: 0.0642 - val_mae: 0.0642 - val_mse: 0.0267 - val_accuracy: 0.9668\n",
      "[16:11:40][epoch 3/3 | file 16/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[16:11:41][epoch 3/3 | file 17/19] Loading and preparing \"blured12to1_withHud_25k__19of19__2021-02-02 13-39-03.npy\"...\n",
      "[16:11:44][epoch 3/3 | file 17/19] Training model...\n",
      "Epoch 1/3\n",
      " 2/71 [..............................] - ETA: 5s - loss: 0.0772 - mae: 0.0772 - mse: 0.0370 - accuracy: 0.9375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0349s vs `on_train_batch_end` time: 0.0628s). Check your callbacks.\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 0.0692 - mae: 0.0692 - mse: 0.0304 - accuracy: 0.9436 - val_loss: 0.0669 - val_mae: 0.0669 - val_mse: 0.0274 - val_accuracy: 0.9600\n",
      "Epoch 2/3\n",
      "71/71 [==============================] - 7s 97ms/step - loss: 0.0692 - mae: 0.0692 - mse: 0.0304 - accuracy: 0.9436 - val_loss: 0.0669 - val_mae: 0.0669 - val_mse: 0.0274 - val_accuracy: 0.9600\n",
      "Epoch 3/3\n",
      "71/71 [==============================] - 7s 98ms/step - loss: 0.0692 - mae: 0.0692 - mse: 0.0304 - accuracy: 0.9436 - val_loss: 0.0669 - val_mae: 0.0669 - val_mse: 0.0274 - val_accuracy: 0.9600\n",
      "[16:12:05][epoch 3/3 | file 17/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[16:12:06][epoch 3/3 | file 18/19] Loading and preparing \"blured12to1_withHud_25k__16of19__2021-02-02 13-35-25.npy\"...\n",
      "[16:12:28][epoch 3/3 | file 18/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 28s - loss: 0.0609 - mae: 0.0609 - mse: 0.0290 - accuracy: 0.9609WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0354s vs `on_train_batch_end` time: 0.0628s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0716 - mae: 0.0716 - mse: 0.0349 - accuracy: 0.9335 - val_loss: 0.0713 - val_mae: 0.0713 - val_mse: 0.0342 - val_accuracy: 0.9328\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0716 - mae: 0.0716 - mse: 0.0349 - accuracy: 0.9335 - val_loss: 0.0713 - val_mae: 0.0713 - val_mse: 0.0342 - val_accuracy: 0.9328\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0716 - mae: 0.0716 - mse: 0.0349 - accuracy: 0.9335 - val_loss: 0.0713 - val_mae: 0.0713 - val_mse: 0.0342 - val_accuracy: 0.9328\n",
      "[16:14:13][epoch 3/3 | file 18/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "[16:14:15][epoch 3/3 | file 19/19] Loading and preparing \"blured12to1_withHud_25k__11of19__2021-02-02 13-31-35.npy\"...\n",
      "[16:14:37][epoch 3/3 | file 19/19] Training model...\n",
      "Epoch 1/3\n",
      "  2/352 [..............................] - ETA: 27s - loss: 0.0557 - mae: 0.0557 - mse: 0.0231 - accuracy: 0.9688WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0339s vs `on_train_batch_end` time: 0.0618s). Check your callbacks.\n",
      "352/352 [==============================] - 34s 97ms/step - loss: 0.0602 - mae: 0.0602 - mse: 0.0236 - accuracy: 0.9730 - val_loss: 0.0609 - val_mae: 0.0609 - val_mse: 0.0237 - val_accuracy: 0.9764\n",
      "Epoch 2/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0602 - mae: 0.0602 - mse: 0.0236 - accuracy: 0.9730 - val_loss: 0.0609 - val_mae: 0.0609 - val_mse: 0.0237 - val_accuracy: 0.9764\n",
      "Epoch 3/3\n",
      "352/352 [==============================] - 35s 99ms/step - loss: 0.0602 - mae: 0.0602 - mse: 0.0236 - accuracy: 0.9730 - val_loss: 0.0609 - val_mae: 0.0609 - val_mse: 0.0237 - val_accuracy: 0.9764\n",
      "[16:16:22][epoch 3/3 | file 19/19] Saving model and appending history...\n",
      "INFO:tensorflow:Assets written to: models 1\\model12_withHud_12to1_deeperModel_sigmoid__02-02-2021 14-19-18\\assets\n",
      "\n",
      "\n",
      "[16:16:24] Training has been finished...\n"
     ]
    }
   ],
   "source": [
    "# import batches of data while training model\n",
    "\n",
    "# Model var\n",
    "model_dir = \"models 1\"\n",
    "exp_model_name = f\"model12_withHud_12to1_deeperModel_sigmoid__{datetime.now().strftime('%d-%m-%Y %H-%M-%S')}\"\n",
    "exp_model_path = os.path.join(model_dir, exp_model_name)\n",
    "use_existing_model = False\n",
    "imp_model_name = \"\"\n",
    "imp_model_path = os.path.join(model_dir, imp_model_name)\n",
    "model = keras.models.load_model(imp_model_path) if use_existing_model else create_deeper_model()\n",
    "\n",
    "# Data var\n",
    "to_import_dir = \"import_these_files\"\n",
    "to_import_path = os.path.join(processed_data_path, to_import_dir)\n",
    "proc_files_paths = [os.path.join(to_import_path, file.name) for file in os.scandir(to_import_path)]\n",
    "\n",
    "# Training var\n",
    "batch_size = 64\n",
    "dataset_epochs = 3\n",
    "file_epochs = 3\n",
    "test_size = 0.1\n",
    "patience = 10\n",
    "my_callbacks = [\n",
    "    ##tf.keras.callbacks.EarlyStopping(patience=patience, restore_best_weights=True),\n",
    "    ##tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    ##tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "histories = []\n",
    "file_cnt = 0\n",
    "\n",
    "\n",
    "print(f\"[{datetime.now().strftime('%H:%M:%S')}] Training is starting...\")\n",
    "\n",
    "for epoch in range(dataset_epochs):\n",
    "    print(f\"\\n\\n[{datetime.now().strftime('%H:%M:%S')}] Epoch {epoch+1} of {dataset_epochs} is starting...\")\n",
    "    file_cnt = 0\n",
    "    np.random.shuffle(proc_files_paths)\n",
    "    for file_path in proc_files_paths:\n",
    "        file_cnt += 1\n",
    "        print(f'\\n[{datetime.now().strftime(\"%H:%M:%S\")}][epoch {epoch+1}/{dataset_epochs} | file {file_cnt}/{len(proc_files_paths)}] Loading and preparing \"{os.path.basename(file_path)}\"...')\n",
    "        \n",
    "        # Load file\n",
    "        training_data = np.load(file_path, allow_pickle=True)\n",
    "        \n",
    "        # \"Split\" into input(X) and output(y)\n",
    "        X = np.array([instance[0] for instance in training_data])\n",
    "        y = np.array([instance[1] for instance in training_data])\n",
    "        del training_data\n",
    "        \n",
    "        # Create train and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "        del X, y\n",
    "\n",
    "        # Add dimension for compatibility with keras CNN model\n",
    "        X_train = np.expand_dims(X_train, -1)\n",
    "        X_test = np.expand_dims(X_test, -1)\n",
    "        \n",
    "        # Train Model\n",
    "        print(f\"[{datetime.now().strftime('%H:%M:%S')}][epoch {epoch+1}/{dataset_epochs} | file {file_cnt}/{len(proc_files_paths)}] Training model...\")\n",
    "        history = model.fit(X_train,\n",
    "                            y_train,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=file_epochs,\n",
    "                            validation_data=(X_test, y_test),\n",
    "                            verbose=1)\n",
    "        \n",
    "        # Save Model\n",
    "        print(f\"[{datetime.now().strftime('%H:%M:%S')}][epoch {epoch+1}/{dataset_epochs} | file {file_cnt}/{len(proc_files_paths)}] Saving model and appending history...\")\n",
    "        histories.append(history)\n",
    "        model.save(exp_model_path)\n",
    "        \n",
    "        del X_train, X_test, y_train, y_test\n",
    "        \n",
    "print(f\"\\n\\n[{datetime.now().strftime('%H:%M:%S')}] Training has been finished...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x25add36cfc8>,\n",
       " <matplotlib.lines.Line2D at 0x25b64ae0788>,\n",
       " <matplotlib.lines.Line2D at 0x25b6525bb88>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(history.history['val_loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.show()\n",
    "plt.plot([hist.history['val_loss'] for hist in histories])\n",
    "# plt.plot(histories[0].history[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_instance(data, index=None):\n",
    "    if index == None:\n",
    "        index = random.randrange(len(data))\n",
    "    plt.imshow(data[index][0], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    print(data[index][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_instance_with_prediction(X_test, y_test, predictions, rand=True):\n",
    "    index = random.randrange(len(X_test))\n",
    "    plt.imshow(X_test[index], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    print(f\"Predicted y: {[round(item, 2) for item in predictions[index]]}\")\n",
    "    print(f\"Actual y: {y_test[index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 100, 240, 64)      3200      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 50, 120, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 50, 120, 128)      73856     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 50, 120, 128)      147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 25, 60, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 192000)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               24576128  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 24,809,284\n",
      "Trainable params: 24,809,284\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "load_model_path = \"models 1\\\\Full_Big_unbalanced_6to1_model_linear 11-11-2020 00-35-04\"\n",
    "model = keras.models.load_model(load_model_path)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess raw files on the hhd and save them on the ssd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _hdd_parse_function(example_proto):\n",
    "    feature_description = {\n",
    "        \"image_raw\": FixedLenFeature([], tf.string),\n",
    "        \"label\" : FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    # Parse the input `tf.train.Example` proto using the dictionary above.\n",
    "    return tf.io.parse_single_example(example_proto, feature_description)\n",
    "\n",
    "\n",
    "def hdd_decode_tfrecord(inst):\n",
    "    inst[\"image_raw\"] = tf.io.parse_tensor(inst[\"image_raw\"], out_type=tf.uint8)\n",
    "    inst[\"label\"] = tf.io.parse_tensor(inst[\"label\"], out_type=tf.float32)\n",
    "    return inst\n",
    "\n",
    "\n",
    "def dataset_to_tensors(ds):\n",
    "    X, y = [], []\n",
    "    for instance in ds:\n",
    "        X.append(instance[\"image_raw\"])\n",
    "        y.append(instance[\"label\"])\n",
    "    return tf.stack(X), tf.stack(y)\n",
    "\n",
    "\n",
    "def create_example(pov_img, nav_img, spd, blur6, blur12, blur24, blur36):\n",
    "    pov_img = tf.convert_to_tensor(pov_img, dtype=tf.uint8)\n",
    "    nav_img = tf.convert_to_tensor(nav_img, dtype=tf.uint8)\n",
    "    spd = tf.convert_to_tensor(spd, dtype=tf.float32)\n",
    "    blur6 = tf.convert_to_tensor(blur6, dtype=tf.float32)\n",
    "    blur12 = tf.convert_to_tensor(blur12, dtype=tf.float32)\n",
    "    blur24 = tf.convert_to_tensor(blur24, dtype=tf.float32)\n",
    "    blur36 = tf.convert_to_tensor(blur36, dtype=tf.float32)\n",
    "\n",
    "    features = {\n",
    "            \"pov\": Feature(bytes_list=BytesList(value=[tf.io.serialize_tensor(pov_img).numpy()])),\n",
    "            \"nav\": Feature(bytes_list=BytesList(value=[tf.io.serialize_tensor(nav_img).numpy()])),\n",
    "            \"spd\": Feature(bytes_list=BytesList(value=[tf.io.serialize_tensor(spd).numpy()])),\n",
    "            \"blured6_keys\": Feature(bytes_list=BytesList(value=[tf.io.serialize_tensor(blur6).numpy()])),\n",
    "            \"blured12_keys\": Feature(bytes_list=BytesList(value=[tf.io.serialize_tensor(blur12).numpy()])),\n",
    "            \"blured24_keys\": Feature(bytes_list=BytesList(value=[tf.io.serialize_tensor(blur24).numpy()])),\n",
    "            \"blured36_keys\": Feature(bytes_list=BytesList(value=[tf.io.serialize_tensor(blur36).numpy()])),\n",
    "            }\n",
    "\n",
    "    return Example(features=Features(feature=features))\n",
    "\n",
    "\n",
    "def blur_1d(inp_list, blur_weights):\n",
    "    blured_list = []\n",
    "    div_factor = blur_weights[0] + sum(blur_weights[1:]) * 2\n",
    "    for index in range(len(inp_list)):\n",
    "        for offset, blur_weight in enumerate(blur_weights):\n",
    "            if offset == 0:\n",
    "                blured_val = blur_weight * inp_list[index]\n",
    "            else:\n",
    "                if index + offset < len(inp_list):\n",
    "                    blured_val += blur_weight * inp_list[index+offset]\n",
    "                else:\n",
    "                    blured_val += blur_weight * inp_list[index]\n",
    "\n",
    "                if index - offset >= 0:\n",
    "                    blured_val += blur_weight * inp_list[index-offset]\n",
    "                else:\n",
    "                    blured_val += blur_weight * inp_list[index]\n",
    "            #print(blured_val)\n",
    "\n",
    "        blured_val /= div_factor\n",
    "        blured_list.append(blured_val)\n",
    "    \n",
    "    return blured_list\n",
    "    \n",
    "\n",
    "def blur_2d(list2d, blur_weights):\n",
    "    blured_list = []\n",
    "    for key_index in range(list2d.shape[1]):\n",
    "        key_list = [instance[key_index] for instance in list2d]\n",
    "        key_list_blured = blur_1d(key_list, blur_weights)\n",
    "            \n",
    "        if key_index == 0:\n",
    "            blured_list = [[val] for val in key_list_blured]\n",
    "        else:\n",
    "            for i in range(len(blured_list)):\n",
    "                blured_list[i].append(key_list_blured[i])\n",
    "                    \n",
    "    return blured_list\n",
    "\n",
    "\n",
    "def detect_speed(img, debugging=False):  \n",
    "    relative_pixel_positions = [((0, 2),(0, 7)),\n",
    "                            ((2, 0),(5, 0)),\n",
    "                            ((2, 10),(5, 10)),\n",
    "                            ((7, 2),(8, 6)),\n",
    "                            ((10, 0),(14, 0)),\n",
    "                            ((10, 10),(14, 10)),\n",
    "                            ((16, 2),(16, 7)),\n",
    "                           ]\n",
    "    pos_ref_1 = (2, 7)\n",
    "    pos_ref_2 = (14, 2)\n",
    "    \n",
    "    offset_num1 = (399, 520)\n",
    "    offset_num2 = (399, 537)\n",
    "    offset_num3 = (399, 554)\n",
    "\n",
    "    offsets = [offset_num1, offset_num2, offset_num3]\n",
    "    \n",
    "    nothing = [0, 0, 0, 0, 0, 0, 0]\n",
    "    zero = [1, 1, 1, 0, 1, 1, 1]\n",
    "    one = [0, 0, 1, 0, 0, 1, 0] \n",
    "    two = [1, 0, 1, 1, 1, 0, 1]\n",
    "    three = [1, 0, 1, 1, 0, 1, 1]\n",
    "    four = [0, 1, 1, 1, 0, 1, 0]\n",
    "    five = [1, 1, 0, 1, 0, 1, 1]\n",
    "    six = [1, 1, 0, 1, 1, 1, 1]\n",
    "    seven = [1, 0, 1, 0, 0, 1, 0]\n",
    "    eight = [1, 1, 1, 1, 1, 1, 1]\n",
    "    nine = [1, 1, 1, 1, 0, 1, 1]\n",
    "    \n",
    "    pixel_mean_threshold = tf.cast(10, tf.float32)\n",
    "    \n",
    "    speed = \"\"\n",
    "\n",
    "    for offset in offsets:\n",
    "        tacho_code = []\n",
    "        # Reference Pixels\n",
    "        h_ref1 = offset[0] + pos_ref_1[0]\n",
    "        w_ref1 = offset[1] + pos_ref_1[1]\n",
    "        h_ref2 = offset[0] + pos_ref_2[0]\n",
    "        w_ref2 = offset[1] + pos_ref_2[1]\n",
    "        ref1 = tf.math.reduce_mean(img[h_ref1, w_ref1])\n",
    "        ref2 = tf.math.reduce_mean(img[h_ref2, w_ref2])\n",
    "        reference = tf.cast(tf.math.reduce_mean([ref1, ref2]), tf.float32)\n",
    "        \n",
    "        for positions in relative_pixel_positions:\n",
    "            values = []\n",
    "            for position in positions:\n",
    "                h_index = position[0]+offset[0]\n",
    "                w_index = position[1]+offset[1]\n",
    "                values.append(img[h_index, w_index].numpy())\n",
    "            mean = tf.cast(tf.math.reduce_mean(values), tf.float32)\n",
    "            if mean < pixel_mean_threshold or mean*4 < reference:\n",
    "                tacho_code.append(1)\n",
    "            else:\n",
    "                tacho_code.append(0)\n",
    "\n",
    "        if tacho_code == nothing or tacho_code == zero:\n",
    "            speed += \"0\"\n",
    "        elif tacho_code == one:\n",
    "            speed += \"1\"\n",
    "        elif tacho_code == two:\n",
    "            speed += \"2\"\n",
    "        elif tacho_code == three:\n",
    "            speed += \"3\"\n",
    "        elif tacho_code == four:\n",
    "            speed += \"4\"\n",
    "        elif tacho_code == five:\n",
    "            speed += \"5\"\n",
    "        elif tacho_code == six:\n",
    "            speed += \"6\"\n",
    "        elif tacho_code == seven:\n",
    "            speed += \"7\"\n",
    "        elif tacho_code == eight:\n",
    "            speed += \"8\"\n",
    "        elif tacho_code == nine:\n",
    "            speed += \"9\"\n",
    "        \n",
    "        elif len(speed) >= 2:\n",
    "            speed += \"5\"\n",
    "            break\n",
    "            \n",
    "        elif len(speed) == 1:\n",
    "            speed += \"50\"\n",
    "            break\n",
    "            \n",
    "        elif len(speed) == 0:\n",
    "            if debugging:\n",
    "                print(f\"SPEED-O-METER DETECTION ERROR\")\n",
    "                print(f\"The first digit couldn't be detected. Setting speed to 220\")\n",
    "                print(\"Tacho_code =\", tacho_code)\n",
    "                raise Exception()\n",
    "            speed += \"220\"\n",
    "            break\n",
    "            \n",
    "        else:\n",
    "            if debugging:\n",
    "                print(f\"SPEED-O-METER DETECTION ERROR\")\n",
    "                print(\"Tacho code is invalid.\")\n",
    "                print(\"Reference ==\", reference)\n",
    "                print(\"Tacho_code =\", tacho_code)\n",
    "                raise Exception()\n",
    "            speed += \"220\"\n",
    "            break\n",
    "\n",
    "    speed = int(speed)\n",
    "    \n",
    "    if speed > 420:\n",
    "        if debugging:\n",
    "            print(f\"SPEED-O-METER DETECTION ERROR\")\n",
    "            print(f'The detected speed of {speed} km/h seems to be a detection error. Setting speed to 220')\n",
    "            raise Exception()\n",
    "        speed = 220\n",
    "        \n",
    "    return speed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process-Export Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base paths\n",
    "hdd_base_path = \"H:\\\\Programming\\\\My Projects\\\\NFSMW-AI\"\n",
    "ssd_base_path = \"F:\\\\1 Desktopfiles\\\\01 Programming\\\\05 My Projects\\\\nfsmw-ai\"\n",
    "# Files get saved to this folder\n",
    "processed_files_dir = \"training_data\\\\processed_data\\\\big_records_preprocessed\\\\\"\n",
    "# pattern of raw files\n",
    "raw_files_pattern = \"raw_training_data\\\\*\\\\*.tfrecord\"\n",
    "# change current directory to hdd\n",
    "os.chdir(hdd_base_path)\n",
    "# collect file names that match the pattern\n",
    "raw_file_paths = tf.data.Dataset.list_files(raw_files_pattern)\n",
    "\n",
    "# SET VARIABLES for Operations\n",
    "# instances per new file\n",
    "instances_per_new_file = 1000\n",
    "\n",
    "# Amount of blur applied to the keys across instances\n",
    "blur_6to1 =list(range(6, 0, -1))\n",
    "blur_12to1 =list(range(12, 0, -1))\n",
    "blur_24to1 =list(range(24, 0, -1))\n",
    "blur_36to1 =list(range(36, 0, -1))\n",
    "\n",
    "# maximum number of keys in the data\n",
    "n_keys = 5\n",
    "\n",
    "# Amount of instances ignored at the beginning and end of raw files\n",
    "cut_off = 50\n",
    "\n",
    "# Map Size\n",
    "nav_size = (112, 112)\n",
    "\n",
    "# pov crop box (offset==top-left corner)\n",
    "offset_height = 130\n",
    "offset_width = 46\n",
    "target_height = 324\n",
    "target_width = 548\n",
    "\n",
    "# number instances to skip when iterating over data\n",
    "n_skip_instances = 1\n",
    "step_size = n_skip_instances + 1\n",
    "\n",
    "for raw_file_path in raw_file_paths:\n",
    "    # set current directory to hdd (for loading)\n",
    "    os.chdir(hdd_base_path)\n",
    "    \n",
    "    # import and parse one file\n",
    "    dataset = tf.data.TFRecordDataset(raw_file_path)\n",
    "    dataset = dataset.map(_hdd_parse_function, num_parallel_calls=-1)\n",
    "    dataset = dataset.map(hdd_decode_tfrecord, num_parallel_calls=-1)\n",
    "    \n",
    "    # turn dataset into tensors\n",
    "    # pov==first person view ; keys==keys being pressed\n",
    "    pov, keys = dataset_to_tensors(dataset)\n",
    "    \n",
    "    if pov.shape[0] < instances_per_new_file * step_size + cut_off * 2:\n",
    "        continue\n",
    "    \n",
    "    # if keys don't include nitro add a zero\n",
    "    while keys.shape[1] < n_keys:\n",
    "        keys = tf.concat([keys, tf.zeros(keys.shape, tf.float32)[:,-1:]], 1)\n",
    "    \n",
    "    # blur keys across instances\n",
    "    blured6_keys = blur_2d(keys, blur_6to1)\n",
    "    blured12_keys = blur_2d(keys, blur_12to1)\n",
    "    blured24_keys = blur_2d(keys, blur_24to1)\n",
    "    blured36_keys = blur_2d(keys, blur_36to1)\n",
    "    \n",
    "    # eather pressing the left or right key\n",
    "    blured6_keys = [[instance[0], tf.math.maximum(0, instance[1]-instance[3]), instance[2], tf.math.maximum(0, instance[3]-instance[1]), instance[4]] for instance in blured6_keys]\n",
    "    blured12_keys = [[instance[0], tf.math.maximum(0, instance[1]-instance[3]), instance[2], tf.math.maximum(0, instance[3]-instance[1]), instance[4]] for instance in blured12_keys]\n",
    "    blured24_keys = [[instance[0], tf.math.maximum(0, instance[1]-instance[3]), instance[2], tf.math.maximum(0, instance[3]-instance[1]), instance[4]] for instance in blured24_keys]\n",
    "    blured36_keys = [[instance[0], tf.math.maximum(0, instance[1]-instance[3]), instance[2], tf.math.maximum(0, instance[3]-instance[1]), instance[4]] for instance in blured36_keys]\n",
    "    \n",
    "    # remove first and last couple instances\n",
    "    pov = pov[cut_off:-cut_off]\n",
    "    blured6_keys = blured6_keys[cut_off:-cut_off]\n",
    "    blured12_keys = blured12_keys[cut_off:-cut_off]\n",
    "    blured24_keys = blured24_keys[cut_off:-cut_off]\n",
    "    blured36_keys = blured36_keys[cut_off:-cut_off]\n",
    "    \n",
    "    # extract map(nav) from pov\n",
    "    nav = pov[:,307:453,26:172,:]\n",
    "    # resize map(nav)\n",
    "    nav = tf.image.resize(nav, nav_size)\n",
    "    nav = tf.cast(nav, tf.uint8)\n",
    "    \n",
    "    # censor map (nav) in pov with a random uniform value\n",
    "    pov = tf.Variable(pov)\n",
    "    pov[:,307:453,26:172,:].assign(tf.cast(tf.random.normal(pov[:,307:453,26:172,:].shape)*255, dtype=tf.uint8))\n",
    "    pov = tf.convert_to_tensor(pov)\n",
    "    \n",
    "    # determine speed\n",
    "    spd = []\n",
    "    for instance in pov:\n",
    "        spd.append(detect_speed(instance))\n",
    "    \n",
    "    # crop pov to bounding box\n",
    "    pov = tf.image.crop_to_bounding_box(pov, offset_height, offset_width, target_height, target_width)\n",
    "    \n",
    "    # tensors into variables\n",
    "    pov = tf.Variable(pov)\n",
    "    nav = tf.Variable(nav)\n",
    "    spd = tf.cast(spd, tf.float32)\n",
    "    spd = tf.Variable(spd)\n",
    "    blured6_keys = tf.Variable(blured6_keys)\n",
    "    blured12_keys = tf.Variable(blured12_keys)\n",
    "    blured24_keys = tf.Variable(blured24_keys)\n",
    "    blured36_keys = tf.Variable(blured36_keys)\n",
    "    \n",
    "    # set current directory to ssd (for saving)\n",
    "    os.chdir(ssd_base_path)\n",
    "    \n",
    "    # save instances to file\n",
    "    file_count = 0\n",
    "    # save to new files While there are enough instances\n",
    "    while pov.shape[0] >= instances_per_new_file * step_size:\n",
    "        file_count += 1\n",
    "        file_name = f\"{file_count}_\" + os.path.basename(raw_file_path.numpy()).decode(\"utf-8\")\n",
    "        file_path = os.path.join(processed_files_dir, file_name)\n",
    "        with tf.io.TFRecordWriter(file_path) as writer:\n",
    "            for i in range(0, instances_per_new_file*step_size, step_size):\n",
    "                tf_example = create_example(pov[i], nav[i], spd[i],\n",
    "                                            blured6_keys[i], blured12_keys[i], blured24_keys[i], blured36_keys[i])\n",
    "                writer.write(tf_example.SerializeToString())\n",
    "        \n",
    "        # remove already saved instances\n",
    "        n_remove = instances_per_new_file * step_size\n",
    "        pov = pov[n_remove:]\n",
    "        nav = nav[n_remove:]\n",
    "        spd = spd[n_remove:]\n",
    "        blured6_keys = blured6_keys[n_remove:]\n",
    "        blured12_keys = blured12_keys[n_remove:]\n",
    "        blured24_keys = blured24_keys[n_remove:]\n",
    "        blured36_keys = blured36_keys[n_remove:]\n",
    "\n",
    "os.chdir(ssd_base_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d\n"
     ]
    }
   ],
   "source": [
    "a = [\"w\", \"a\", \"s\", \"d\"]\n",
    "print(a[3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv",
   "language": "python",
   "name": "local-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
