{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Conv2D, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "\n",
    "data_dir = \"training_data\"\n",
    "processed_data_dir = \"processed_data\"\n",
    "raw_data_dirs = [\"raw_training_6_143_1st-P__rev-high99_noHud\",\n",
    "                 \"raw_training_7_77_1st-P__norm-high99_noHud\",\n",
    "                 \"raw_training_8_53_1st-P__norm-high99_noHud\",\n",
    "                 \"raw_training_9_52_1st-P__rev-high99_noHud\",]\n",
    "\n",
    "raw_data_paths = [os.path.join(data_dir, train_dir) for train_dir in raw_data_dirs]\n",
    "processed_data_path = os.path.join(data_dir, processed_data_dir)\n",
    "\n",
    "raw_file_paths = []\n",
    "for dir in raw_data_paths:\n",
    "    paths = [os.path.join(dir, file.name) for file in os.scandir(dir)]\n",
    "    raw_file_paths += paths\n",
    "\n",
    "random.shuffle(raw_file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Raw Training Files\n",
    "\n",
    "# 0) Setup parameters and variables\n",
    "# 1) Iterate through raw_training_files.\n",
    "# 2) Blur the keyboard strokes with close instances\n",
    "# 3) Append file to bigger output file\n",
    "# 4) Scale input values by 255.\n",
    "# 5) Shuffle instances within the new files.\n",
    "# 6) Save new files as processed.\n",
    "\n",
    "# 0) Set Parameters\n",
    "blur_321 = list(range(3, 0, -1))\n",
    "blur_6to1 =list(range(6, 0, -1))\n",
    "blur_12to1 =list(range(12, 0, -1))\n",
    "blur_24to1 =list(range(24, 0, -1))\n",
    "\n",
    "blur = blur_12to1\n",
    "\n",
    "n_combined_files = 25\n",
    "n_output_files = ceil(len(raw_file_paths)/n_combined_files)\n",
    "\n",
    "\n",
    "print(f\"[{datetime.now().strftime('%H:%M:%S')}] File Processing is starting...\")\n",
    "\n",
    "# 1) Iterate over number of output files\n",
    "for j in range(n_output_files):\n",
    "    blured_train_file = None\n",
    "    print(f\"\\n[{datetime.now().strftime('%H:%M:%S')}][new file {j+1}/{n_output_files}] New Array has been created...\")\n",
    "    file_name = f\"blured12to1__25k__f{j+1}of{n_output_files}__{datetime.now().strftime('%Y-%m-%d %H-%M-%S')}.npy\"\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}][new file {j+1}/{n_output_files}] Loading, bluring and appending instances...\")\n",
    "    \n",
    "    # 1) Iterate over each inp-file of out-file\n",
    "    for i in range(0, n_combined_files):\n",
    "        index = j*n_combined_files+i\n",
    "        if index >= len(raw_file_paths):\n",
    "               break\n",
    "        file = np.load(raw_file_paths[index], allow_pickle=True)\n",
    "        \n",
    "        # 2) Blur\n",
    "        blured_keys = blur_lists_of_list([instance[1] for instance in file], blur)\n",
    "        file = [[file[i][0], blured_keys[i]] for i in range(len(file))]\n",
    "        del blured_keys\n",
    "        \n",
    "        # 3) Append\n",
    "        if blured_train_file == None:\n",
    "            blured_train_file = file\n",
    "        else:\n",
    "            blured_train_file = np.append(blured_train_file, file, axis=0)\n",
    "        #print(np.shape(blured_train_file))\n",
    "        del file\n",
    "\n",
    "    # 4) Scale\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}][new file {j+1}/{n_output_files}] Data is getting scaled...\")\n",
    "    for i in range(len(blured_train_file)):\n",
    "        blured_train_file[i][0] = blured_train_file[i][0] / 255\n",
    "        ##unblured_train_file = blured_train_file.copy()\n",
    "\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}][new file {j+1}/{n_output_files}] key strokes are getting blured between frames...\")\n",
    "\n",
    "\n",
    "    # 5) Shuffle\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}][new file {j+1}/{n_output_files}] Instances get shuffled...\")\n",
    "    np.random.shuffle(blured_train_file)\n",
    "\n",
    "    # 6) Save\n",
    "    print(f'[{datetime.now().strftime(\"%H:%M:%S\")}][new file {j+1}/{n_output_files}] \"{file_name}\" is getting saved...this might take a while... (shape={np.shape(blured_train_file)})')\n",
    "    np.save(os.path.join(processed_data_path, file_name), blured_train_file)\n",
    "    print(f'[{datetime.now().strftime(\"%H:%M:%S\")}][new file {j+1}/{n_output_files}] \"{file_name}\" has been saved... shape={np.shape(blured_train_file)}')\n",
    "    del blured_train_file\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(f\"[{datetime.now().strftime('%H:%M:%S')}]File Processing has been finished...\")\n",
    "\n",
    "# CHECK IF FILE WAS CORRECTLY BLURRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blur Lists and 2d-Lists\n",
    "\n",
    "blured_list = []\n",
    "\n",
    "def blur_list(inp_list, blur_weights):\n",
    "    blured_list = []\n",
    "    div_factor = blur_weights[0] + sum(blur_weights[1:]) * 2\n",
    "    for index in range(len(inp_list)):\n",
    "        for offset, blur_weight in enumerate(blur_weights):\n",
    "            if offset == 0:\n",
    "                blured_val = blur_weight * inp_list[index]\n",
    "            else:\n",
    "                if index + offset < len(inp_list):\n",
    "                    blured_val += blur_weight * inp_list[index+offset]\n",
    "                else:\n",
    "                    blured_val += blur_weight * inp_list[index]\n",
    "\n",
    "                if index - offset >= 0:\n",
    "                    blured_val += blur_weight * inp_list[index-offset]\n",
    "                else:\n",
    "                    blured_val += blur_weight * inp_list[index]\n",
    "            #print(blured_val)\n",
    "\n",
    "        blured_val /= div_factor\n",
    "        blured_list.append(blured_val)\n",
    "    \n",
    "    return blured_list\n",
    "    \n",
    "\n",
    "def blur_lists_of_list(list2d, blur_weights):\n",
    "    blured_list = []\n",
    "    for key_index in range(len(list2d[0])):\n",
    "        key_list = [instance[key_index] for instance in list2d]\n",
    "        key_list_blured = blur_list(key_list, blur_weights)\n",
    "            \n",
    "        if key_index == 0:\n",
    "            blured_list = [[val] for val in key_list_blured]\n",
    "        else:\n",
    "            for i in range(len(blured_list)):\n",
    "                blured_list[i].append(key_list_blured[i])\n",
    "                    \n",
    "    return blured_list\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process imported data\n",
    "\n",
    "proc_file_path = os.path.join(processed_data_path, \"mid_size_train_file.npy\")\n",
    "\n",
    "# Load file\n",
    "training_data = np.load(proc_file_path, allow_pickle=True)\n",
    "# \"Split\" into input(X) and output(y)\n",
    "X = np.array([instance[0] for instance in training_data])\n",
    "y = np.array([instance[1] for instance in training_data])\n",
    "del training_data\n",
    "\n",
    "# Create train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Add dimension for compatibility with keras CNN model\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "X_test = np.expand_dims(X_test, -1)\n",
    "\n",
    "# delete unused variables for saving ram\n",
    "del X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model\n",
    "\n",
    "def create_new_model():\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(64, 7, activation=\"relu\", padding=\"same\"),\n",
    "        keras.layers.MaxPooling2D(2),\n",
    "        keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "        keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "        keras.layers.MaxPooling2D(2),\n",
    "        #keras.layers.Dropout(0.5),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(128, activation=\"relu\"),\n",
    "        keras.layers.Dense(64, activation=\"relu\"),\n",
    "        #keras.layers.Dropout(0.5),\n",
    "        keras.layers.Dense(4, activation=\"linear\")\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='mae',\n",
    "                  optimizer='adam',\n",
    "#                  metrics=['accuracy']\n",
    "                 )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Model\n",
    "\n",
    "def create_deeper_model():\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(128, 5, activation=\"relu\", padding=\"same\"),\n",
    "        keras.layers.MaxPooling2D(2),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "        keras.layers.MaxPooling2D(2),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "        keras.layers.MaxPooling2D(2),\n",
    "        keras.layers.Dropout(0.5),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(128, activation=\"relu\"),\n",
    "        keras.layers.Dense(64, activation=\"relu\"),\n",
    "        keras.layers.Dense(4, activation=\"linear\")\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='mae',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy']\n",
    "                 )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 1\n",
    "patience = 5\n",
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=patience),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "\n",
    "history = model.fit(X_train , y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import batches of data while training model\n",
    "\n",
    "# Model var\n",
    "model_dir = \"keras_models\"\n",
    "exp_model_name = f\"Full_noHud_dirMix_12to1_deeper_model_linear {datetime.now().strftime('%d-%m-%Y %H-%M-%S')}\"\n",
    "exp_model_path = os.path.join(model_dir, exp_model_name)\n",
    "use_existing_model = False\n",
    "imp_model_name = \"\"\n",
    "imp_model_path = os.path.join(model_dir, imp_model_name)\n",
    "model = keras.models.load_model(imp_model_path) if use_existing_model else create_deeper_model()\n",
    "\n",
    "# Data var\n",
    "to_import_dir = \"import_these_files\"\n",
    "to_import_path = os.path.join(processed_data_path, to_import_dir)\n",
    "proc_files_paths = [os.path.join(to_import_path, file.name) for file in os.scandir(to_import_path)]\n",
    "\n",
    "# Training var\n",
    "batch_size = 64\n",
    "dataset_epochs = 5\n",
    "file_epochs = 3\n",
    "test_size = 0.1\n",
    "patience = 10\n",
    "my_callbacks = [\n",
    "    ##tf.keras.callbacks.EarlyStopping(patience=patience, restore_best_weights=True),\n",
    "    ##tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    ##tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "histories = []\n",
    "file_cnt = 0\n",
    "\n",
    "\n",
    "print(f\"[{datetime.now().strftime('%H:%M:%S')}] Training is starting...\")\n",
    "\n",
    "for epoch in range(dataset_epochs):\n",
    "    print(f\"\\n\\n[{datetime.now().strftime('%H:%M:%S')}] Epoch {epoch+1} of {dataset_epochs} is starting...\")\n",
    "    file_cnt = 0\n",
    "    np.random.shuffle(proc_files_paths)\n",
    "    for file_path in proc_files_paths:\n",
    "        file_cnt += 1\n",
    "        print(f'\\n[{datetime.now().strftime(\"%H:%M:%S\")}][epoch {epoch+1}/{dataset_epochs} | file {file_cnt}/{len(proc_files_paths)}] Loading and preparing \"{os.path.basename(file_path)}\"...')\n",
    "        \n",
    "        # Load file\n",
    "        training_data = np.load(file_path, allow_pickle=True)\n",
    "        \n",
    "        # \"Split\" into input(X) and output(y)\n",
    "        X = np.array([instance[0] for instance in training_data])\n",
    "        y = np.array([instance[1] for instance in training_data])\n",
    "        del training_data\n",
    "        \n",
    "        # Create train and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "        del X, y\n",
    "\n",
    "        # Add dimension for compatibility with keras CNN model\n",
    "        X_train = np.expand_dims(X_train, -1)\n",
    "        X_test = np.expand_dims(X_test, -1)\n",
    "        \n",
    "        # Train Model\n",
    "        print(f\"[{datetime.now().strftime('%H:%M:%S')}][epoch {epoch+1}/{dataset_epochs} | file {file_cnt}/{len(proc_files_paths)}] Training model...\")\n",
    "        history = model.fit(X_train,\n",
    "                            y_train,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=file_epochs,\n",
    "                            validation_data=(X_test, y_test),\n",
    "                            verbose=1)\n",
    "        \n",
    "        # Save Model\n",
    "        print(f\"[{datetime.now().strftime('%H:%M:%S')}][epoch {epoch+1}/{dataset_epochs} | file {file_cnt}/{len(proc_files_paths)}] Saving model and appending history...\")\n",
    "        histories.append(history)\n",
    "        model.save(exp_model_path)\n",
    "        \n",
    "        del X_train, X_test, y_train, y_test\n",
    "        \n",
    "print(f\"\\n\\n[{datetime.now().strftime('%H:%M:%S')}] Training has been finished...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history['val_loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_instance(data, random=True):\n",
    "    index = random.randrange(len(data))\n",
    "    plt.imshow(data[index][0], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    print(data[index][1])\n",
    "    print(data[index][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_instance_with_prediction(X_test, y_test, predictions, random=True):\n",
    "    index = random.randrange(len(X_test))\n",
    "    plt.imshow(X_test[index], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    print(f\"Predicted y: {[round(item, 2) for item in predictions[index]]}\")\n",
    "    print(f\"Actual y: {y_test[index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess raw files on the hhd and save them on the ssd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _hdd_parse_function(example_proto):\n",
    "    feature_description = {\n",
    "        \"image_raw\": FixedLenFeature([], tf.string),\n",
    "        \"label\" : FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    # Parse the input `tf.train.Example` proto using the dictionary above.\n",
    "    return tf.io.parse_single_example(example_proto, feature_description)\n",
    "\n",
    "\n",
    "def hdd_decode_tfrecord(inst):\n",
    "    inst[\"image_raw\"] = tf.io.parse_tensor(inst[\"image_raw\"], out_type=tf.uint8)\n",
    "    inst[\"label\"] = tf.io.parse_tensor(inst[\"label\"], out_type=tf.float32)\n",
    "    return inst\n",
    "\n",
    "\n",
    "def dataset_to_tensors(ds):\n",
    "    X, y = [], []\n",
    "    for instance in ds:\n",
    "        X.append(instance[\"image_raw\"])\n",
    "        y.append(instance[\"label\"])\n",
    "    return tf.stack(X), tf.stack(y)\n",
    "\n",
    "\n",
    "def create_example(pov_img, nav_img, spd, blur6, blur12, blur24, blur36):\n",
    "    pov_img = tf.convert_to_tensor(pov_img, dtype=tf.uint8)\n",
    "    nav_img = tf.convert_to_tensor(nav_img, dtype=tf.uint8)\n",
    "    spd = tf.convert_to_tensor(spd, dtype=tf.float32)\n",
    "    blur6 = tf.convert_to_tensor(blur6, dtype=tf.float32)\n",
    "    blur12 = tf.convert_to_tensor(blur12, dtype=tf.float32)\n",
    "    blur24 = tf.convert_to_tensor(blur24, dtype=tf.float32)\n",
    "    blur36 = tf.convert_to_tensor(blur36, dtype=tf.float32)\n",
    "\n",
    "    features = {\n",
    "            \"pov\": Feature(bytes_list=BytesList(value=[tf.io.serialize_tensor(pov_img).numpy()])),\n",
    "            \"nav\": Feature(bytes_list=BytesList(value=[tf.io.serialize_tensor(nav_img).numpy()])),\n",
    "            \"spd\": Feature(bytes_list=BytesList(value=[tf.io.serialize_tensor(spd).numpy()])),\n",
    "            \"blured6_keys\": Feature(bytes_list=BytesList(value=[tf.io.serialize_tensor(blur6).numpy()])),\n",
    "            \"blured12_keys\": Feature(bytes_list=BytesList(value=[tf.io.serialize_tensor(blur12).numpy()])),\n",
    "            \"blured24_keys\": Feature(bytes_list=BytesList(value=[tf.io.serialize_tensor(blur24).numpy()])),\n",
    "            \"blured36_keys\": Feature(bytes_list=BytesList(value=[tf.io.serialize_tensor(blur36).numpy()])),\n",
    "            }\n",
    "\n",
    "    return Example(features=Features(feature=features))\n",
    "\n",
    "\n",
    "def blur_1d(inp_list, blur_weights):\n",
    "    blured_list = []\n",
    "    div_factor = blur_weights[0] + sum(blur_weights[1:]) * 2\n",
    "    for index in range(len(inp_list)):\n",
    "        for offset, blur_weight in enumerate(blur_weights):\n",
    "            if offset == 0:\n",
    "                blured_val = blur_weight * inp_list[index]\n",
    "            else:\n",
    "                if index + offset < len(inp_list):\n",
    "                    blured_val += blur_weight * inp_list[index+offset]\n",
    "                else:\n",
    "                    blured_val += blur_weight * inp_list[index]\n",
    "\n",
    "                if index - offset >= 0:\n",
    "                    blured_val += blur_weight * inp_list[index-offset]\n",
    "                else:\n",
    "                    blured_val += blur_weight * inp_list[index]\n",
    "            #print(blured_val)\n",
    "\n",
    "        blured_val /= div_factor\n",
    "        blured_list.append(blured_val)\n",
    "    \n",
    "    return blured_list\n",
    "    \n",
    "\n",
    "def blur_2d(list2d, blur_weights):\n",
    "    blured_list = []\n",
    "    for key_index in range(list2d.shape[1]):\n",
    "        key_list = [instance[key_index] for instance in list2d]\n",
    "        key_list_blured = blur_1d(key_list, blur_weights)\n",
    "            \n",
    "        if key_index == 0:\n",
    "            blured_list = [[val] for val in key_list_blured]\n",
    "        else:\n",
    "            for i in range(len(blured_list)):\n",
    "                blured_list[i].append(key_list_blured[i])\n",
    "                    \n",
    "    return blured_list\n",
    "\n",
    "\n",
    "def detect_speed(img, debugging=False):  \n",
    "    relative_pixel_positions = [((0, 2),(0, 7)),\n",
    "                            ((2, 0),(5, 0)),\n",
    "                            ((2, 10),(5, 10)),\n",
    "                            ((7, 2),(8, 6)),\n",
    "                            ((10, 0),(14, 0)),\n",
    "                            ((10, 10),(14, 10)),\n",
    "                            ((16, 2),(16, 7)),\n",
    "                           ]\n",
    "    pos_ref_1 = (2, 7)\n",
    "    pos_ref_2 = (14, 2)\n",
    "    \n",
    "    offset_num1 = (399, 520)\n",
    "    offset_num2 = (399, 537)\n",
    "    offset_num3 = (399, 554)\n",
    "\n",
    "    offsets = [offset_num1, offset_num2, offset_num3]\n",
    "    \n",
    "    nothing = [0, 0, 0, 0, 0, 0, 0]\n",
    "    zero = [1, 1, 1, 0, 1, 1, 1]\n",
    "    one = [0, 0, 1, 0, 0, 1, 0] \n",
    "    two = [1, 0, 1, 1, 1, 0, 1]\n",
    "    three = [1, 0, 1, 1, 0, 1, 1]\n",
    "    four = [0, 1, 1, 1, 0, 1, 0]\n",
    "    five = [1, 1, 0, 1, 0, 1, 1]\n",
    "    six = [1, 1, 0, 1, 1, 1, 1]\n",
    "    seven = [1, 0, 1, 0, 0, 1, 0]\n",
    "    eight = [1, 1, 1, 1, 1, 1, 1]\n",
    "    nine = [1, 1, 1, 1, 0, 1, 1]\n",
    "    \n",
    "    pixel_mean_threshold = tf.cast(10, tf.float32)\n",
    "    \n",
    "    speed = \"\"\n",
    "\n",
    "    for offset in offsets:\n",
    "        tacho_code = []\n",
    "        # Reference Pixels\n",
    "        h_ref1 = offset[0] + pos_ref_1[0]\n",
    "        w_ref1 = offset[1] + pos_ref_1[1]\n",
    "        h_ref2 = offset[0] + pos_ref_2[0]\n",
    "        w_ref2 = offset[1] + pos_ref_2[1]\n",
    "        ref1 = tf.math.reduce_mean(img[h_ref1, w_ref1])\n",
    "        ref2 = tf.math.reduce_mean(img[h_ref2, w_ref2])\n",
    "        reference = tf.cast(tf.math.reduce_mean([ref1, ref2]), tf.float32)\n",
    "        \n",
    "        for positions in relative_pixel_positions:\n",
    "            values = []\n",
    "            for position in positions:\n",
    "                h_index = position[0]+offset[0]\n",
    "                w_index = position[1]+offset[1]\n",
    "                values.append(img[h_index, w_index].numpy())\n",
    "            mean = tf.cast(tf.math.reduce_mean(values), tf.float32)\n",
    "            if mean < pixel_mean_threshold or mean*4 < reference:\n",
    "                tacho_code.append(1)\n",
    "            else:\n",
    "                tacho_code.append(0)\n",
    "\n",
    "        if tacho_code == nothing or tacho_code == zero:\n",
    "            speed += \"0\"\n",
    "        elif tacho_code == one:\n",
    "            speed += \"1\"\n",
    "        elif tacho_code == two:\n",
    "            speed += \"2\"\n",
    "        elif tacho_code == three:\n",
    "            speed += \"3\"\n",
    "        elif tacho_code == four:\n",
    "            speed += \"4\"\n",
    "        elif tacho_code == five:\n",
    "            speed += \"5\"\n",
    "        elif tacho_code == six:\n",
    "            speed += \"6\"\n",
    "        elif tacho_code == seven:\n",
    "            speed += \"7\"\n",
    "        elif tacho_code == eight:\n",
    "            speed += \"8\"\n",
    "        elif tacho_code == nine:\n",
    "            speed += \"9\"\n",
    "        \n",
    "        elif len(speed) >= 2:\n",
    "            speed += \"5\"\n",
    "            break\n",
    "            \n",
    "        elif len(speed) == 1:\n",
    "            speed += \"50\"\n",
    "            break\n",
    "            \n",
    "        elif len(speed) == 0:\n",
    "            if debugging:\n",
    "                print(f\"SPEED-O-METER DETECTION ERROR\")\n",
    "                print(f\"The first digit couldn't be detected. Setting speed to 220\")\n",
    "                print(\"Tacho_code =\", tacho_code)\n",
    "                raise Exception()\n",
    "            speed += \"220\"\n",
    "            break\n",
    "            \n",
    "        else:\n",
    "            if debugging:\n",
    "                print(f\"SPEED-O-METER DETECTION ERROR\")\n",
    "                print(\"Tacho code is invalid.\")\n",
    "                print(\"Reference ==\", reference)\n",
    "                print(\"Tacho_code =\", tacho_code)\n",
    "                raise Exception()\n",
    "            speed += \"220\"\n",
    "            break\n",
    "\n",
    "    speed = int(speed)\n",
    "    \n",
    "    if speed > 420:\n",
    "        if debugging:\n",
    "            print(f\"SPEED-O-METER DETECTION ERROR\")\n",
    "            print(f'The detected speed of {speed} km/h seems to be a detection error. Setting speed to 220')\n",
    "            raise Exception()\n",
    "        speed = 220\n",
    "        \n",
    "    return speed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process-Export Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base paths\n",
    "hdd_base_path = \"H:\\\\Programming\\\\My Projects\\\\NFSMW-AI\"\n",
    "ssd_base_path = \"F:\\\\1 Desktopfiles\\\\01 Programming\\\\05 My Projects\\\\nfsmw-ai\"\n",
    "# Files get saved to this folder\n",
    "processed_files_dir = \"training_data\\\\processed_data\\\\big_records_preprocessed\\\\\"\n",
    "# pattern of raw files\n",
    "raw_files_pattern = \"raw_training_data\\\\*\\\\*.tfrecord\"\n",
    "# change current directory to hdd\n",
    "os.chdir(hdd_base_path)\n",
    "# collect file names that match the pattern\n",
    "raw_file_paths = tf.data.Dataset.list_files(raw_files_pattern)\n",
    "\n",
    "# SET VARIABLES for Operations\n",
    "# instances per new file\n",
    "instances_per_new_file = 1000\n",
    "\n",
    "# Amount of blur applied to the keys across instances\n",
    "blur_6to1 =list(range(6, 0, -1))\n",
    "blur_12to1 =list(range(12, 0, -1))\n",
    "blur_24to1 =list(range(24, 0, -1))\n",
    "blur_36to1 =list(range(36, 0, -1))\n",
    "\n",
    "# maximum number of keys in the data\n",
    "n_keys = 5\n",
    "\n",
    "# Amount of instances ignored at the beginning and end of raw files\n",
    "cut_off = 50\n",
    "\n",
    "# Map Size\n",
    "nav_size = (112, 112)\n",
    "\n",
    "# pov crop box (offset==top-left corner)\n",
    "offset_height = 130\n",
    "offset_width = 46\n",
    "target_height = 324\n",
    "target_width = 548\n",
    "\n",
    "# number instances to skip when iterating over data\n",
    "n_skip_instances = 1\n",
    "step_size = n_skip_instances + 1\n",
    "\n",
    "for raw_file_path in raw_file_paths:\n",
    "    # set current directory to hdd (for loading)\n",
    "    os.chdir(hdd_base_path)\n",
    "    \n",
    "    # import and parse one file\n",
    "    dataset = tf.data.TFRecordDataset(raw_file_path)\n",
    "    dataset = dataset.map(_hdd_parse_function, num_parallel_calls=-1)\n",
    "    dataset = dataset.map(hdd_decode_tfrecord, num_parallel_calls=-1)\n",
    "    \n",
    "    # turn dataset into tensors\n",
    "    # pov==first person view ; keys==keys being pressed\n",
    "    pov, keys = dataset_to_tensors(dataset)\n",
    "    \n",
    "    if pov.shape[0] < instances_per_new_file * step_size + cut_off * 2:\n",
    "        continue\n",
    "    \n",
    "    # if keys don't include nitro add a zero\n",
    "    while keys.shape[1] < n_keys:\n",
    "        keys = tf.concat([keys, tf.zeros(keys.shape, tf.float32)[:,-1:]], 1)\n",
    "    \n",
    "    # blur keys across instances\n",
    "    blured6_keys = blur_2d(keys, blur_6to1)\n",
    "    blured12_keys = blur_2d(keys, blur_12to1)\n",
    "    blured24_keys = blur_2d(keys, blur_24to1)\n",
    "    blured36_keys = blur_2d(keys, blur_36to1)\n",
    "    \n",
    "    # eather pressing the left or right key\n",
    "    blured6_keys = [[instance[0], tf.math.maximum(0, instance[1]-instance[3]), instance[2], tf.math.maximum(0, instance[3]-instance[1]), instance[4]] for instance in blured6_keys]\n",
    "    blured12_keys = [[instance[0], tf.math.maximum(0, instance[1]-instance[3]), instance[2], tf.math.maximum(0, instance[3]-instance[1]), instance[4]] for instance in blured12_keys]\n",
    "    blured24_keys = [[instance[0], tf.math.maximum(0, instance[1]-instance[3]), instance[2], tf.math.maximum(0, instance[3]-instance[1]), instance[4]] for instance in blured24_keys]\n",
    "    blured36_keys = [[instance[0], tf.math.maximum(0, instance[1]-instance[3]), instance[2], tf.math.maximum(0, instance[3]-instance[1]), instance[4]] for instance in blured36_keys]\n",
    "    \n",
    "    # remove first and last couple instances\n",
    "    pov = pov[cut_off:-cut_off]\n",
    "    blured6_keys = blured6_keys[cut_off:-cut_off]\n",
    "    blured12_keys = blured12_keys[cut_off:-cut_off]\n",
    "    blured24_keys = blured24_keys[cut_off:-cut_off]\n",
    "    blured36_keys = blured36_keys[cut_off:-cut_off]\n",
    "    \n",
    "    # extract map(nav) from pov\n",
    "    nav = pov[:,307:453,26:172,:]\n",
    "    # resize map(nav)\n",
    "    nav = tf.image.resize(nav, nav_size)\n",
    "    nav = tf.cast(nav, tf.uint8)\n",
    "    \n",
    "    # censor map (nav) in pov with a random uniform value\n",
    "    pov = tf.Variable(pov)\n",
    "    pov[:,307:453,26:172,:].assign(tf.cast(tf.random.normal(pov[:,307:453,26:172,:].shape)*255, dtype=tf.uint8))\n",
    "    pov = tf.convert_to_tensor(pov)\n",
    "    \n",
    "    # determine speed\n",
    "    spd = []\n",
    "    for instance in pov:\n",
    "        spd.append(detect_speed(instance))\n",
    "    \n",
    "    # crop pov to bounding box\n",
    "    pov = tf.image.crop_to_bounding_box(pov, offset_height, offset_width, target_height, target_width)\n",
    "    \n",
    "    # tensors into variables\n",
    "    pov = tf.Variable(pov)\n",
    "    nav = tf.Variable(nav)\n",
    "    spd = tf.cast(spd, tf.float32)\n",
    "    spd = tf.Variable(spd)\n",
    "    blured6_keys = tf.Variable(blured6_keys)\n",
    "    blured12_keys = tf.Variable(blured12_keys)\n",
    "    blured24_keys = tf.Variable(blured24_keys)\n",
    "    blured36_keys = tf.Variable(blured36_keys)\n",
    "    \n",
    "    # set current directory to ssd (for saving)\n",
    "    os.chdir(ssd_base_path)\n",
    "    \n",
    "    # save instances to file\n",
    "    file_count = 0\n",
    "    # save to new files While there are enough instances\n",
    "    while pov.shape[0] >= instances_per_new_file * step_size:\n",
    "        file_count += 1\n",
    "        file_name = f\"{file_count}_\" + os.path.basename(raw_file_path.numpy()).decode(\"utf-8\")\n",
    "        file_path = os.path.join(processed_files_dir, file_name)\n",
    "        with tf.io.TFRecordWriter(file_path) as writer:\n",
    "            for i in range(0, instances_per_new_file*step_size, step_size):\n",
    "                tf_example = create_example(pov[i], nav[i], spd[i],\n",
    "                                            blured6_keys[i], blured12_keys[i], blured24_keys[i], blured36_keys[i])\n",
    "                writer.write(tf_example.SerializeToString())\n",
    "        \n",
    "        # remove already saved instances\n",
    "        n_remove = instances_per_new_file * step_size\n",
    "        pov = pov[n_remove:]\n",
    "        nav = nav[n_remove:]\n",
    "        spd = spd[n_remove:]\n",
    "        blured6_keys = blured6_keys[n_remove:]\n",
    "        blured12_keys = blured12_keys[n_remove:]\n",
    "        blured24_keys = blured24_keys[n_remove:]\n",
    "        blured36_keys = blured36_keys[n_remove:]\n",
    "\n",
    "os.chdir(ssd_base_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv",
   "language": "python",
   "name": "local-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
